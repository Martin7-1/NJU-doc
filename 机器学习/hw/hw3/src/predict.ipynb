{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def convert_effect_to_int(effect: str) -> int:\n",
    "    if effect == 'Extremely Severe Side Effects':\n",
    "        return 1\n",
    "    elif effect == 'Severe Side Effects':\n",
    "        return 2\n",
    "    elif effect == 'Moderate Side Effects':\n",
    "        return 3\n",
    "    elif effect == 'Mild Side Effects':\n",
    "        return 4\n",
    "    elif effect == 'No Side Effects':\n",
    "        return 5\n",
    "\n",
    "    print(\"没有该 side effect\")\n",
    "    return -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 获取标签最多的那一类\n",
    "def get_most_label(data):\n",
    "    data_label = data.iloc[:, -1]\n",
    "    label_sort = data_label.value_counts(sort=True)\n",
    "    return label_sort.keys()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      usefulCount  sideEffects  rating\n",
      "0              22            4       5\n",
      "1              17            2       4\n",
      "2               3            5       5\n",
      "3              35            4       5\n",
      "4               4            2       5\n",
      "...           ...          ...     ...\n",
      "6994           11            4       5\n",
      "6995            0            5       4\n",
      "6996           79            4       5\n",
      "6997            1            5       1\n",
      "6998            2            5       3\n",
      "\n",
      "[6999 rows x 3 columns]\n",
      "{'usefulCount': [22, 17, 3, 35, 4, 13, 1, 32, 21, 7, 57, 19, 44, 14, 26, 24, 9, 15, 43, 27, 10, 18, 47, 38, 42, 0, 12, 55, 75, 20, 6, 49, 2, 5, 104, 16, 36, 125, 51, 33, 88, 228, 80, 45, 34, 159, 58, 31, 60, 11, 224, 63, 84, 8, 28, 48, 62, 82, 81, 23, 25, 30, 59, 41, 142, 110, 29, 52, 37, 90, 68, 175, 40, 66, 171, 73, 150, 101, 70, 117, 470, 61, 157, 86, 69, 145, 50, 206, 77, 46, 76, 113, 283, 89, 199, 67, 182, 91, 212, 134, 121, 124, 193, 126, 163, 39, 64, 114, 154, 54, 108, 152, 65, 191, 85, 116, 381, 109, 71, 107, 96, 98, 156, 118, 56, 72, 155, 122, 384, 130, 92, 146, 79, 174, 83, 184, 140, 185, 93, 53, 210, 141, 302, 97, 253, 270, 169, 165, 251, 272, 74, 102, 87, 94, 133, 131, 190, 105, 160, 198, 120, 178, 123, 78, 194, 176, 144, 180, 162, 115, 137, 262, 95, 167, 99, 128, 177, 119, 235, 103, 181, 139, 136, 680, 179, 332, 148, 389, 226, 138, 204, 168, 949, 219, 111, 213, 106, 135, 127, 308, 218, 112, 291, 359, 197, 695, 151, 249, 203, 269, 100, 149, 247, 275, 195, 172, 559, 440, 158, 143, 132, 215, 161], 'sideEffects': [4, 2, 5, 1, 3]}\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../决策树数据集/training.csv\"\n",
    "train_data = pd.read_csv(train_path)\n",
    "# 预处理，删除无用的列\n",
    "train_data = train_data.drop(columns=['recordId', 'drugName', 'condition', 'reviewComment', 'date'])\n",
    "train_data['sideEffects'] = train_data['sideEffects'].apply(lambda effect: convert_effect_to_int(effect))\n",
    "print(train_data)\n",
    "# 统计每个特征的取值情况\n",
    "column_count = dict([(ds, list(pd.unique(train_data[ds]))) for ds in train_data.iloc[:, :-1].columns])\n",
    "print(column_count)\n",
    "# 先给出连续的特征\n",
    "continuous_features = ['usefulCount']\n",
    "most_label = get_most_label(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 计算信息熵\n",
    "def cal_information_entropy(data):\n",
    "    data_label = data.iloc[:, -1]\n",
    "    # 总共有多少类\n",
    "    label_class = data_label.value_counts()\n",
    "    ent = 0\n",
    "    for k in label_class.keys():\n",
    "        p_k = label_class[k] / len(data_label)\n",
    "        ent += -p_k * np.log2(p_k)\n",
    "    return ent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 对于离散特征a，计算给定数据属性a的信息增益\n",
    "def cal_information_gain(data, a):\n",
    "    ent = cal_information_entropy(data)\n",
    "    # 特征有多少种可能\n",
    "    feature_class = data[a].value_counts()\n",
    "    gain = 0\n",
    "    for v in feature_class.keys():\n",
    "        weight = feature_class[v] / data.shape[0]\n",
    "        ent_val = cal_information_entropy(data.loc[data[a] == v])\n",
    "        gain += weight * ent_val\n",
    "    return ent - gain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 对于连续特征b，计算给定数据属性b的信息增益\n",
    "def cal_information_gain_continuous(data, a):\n",
    "    # 总共有n条数据，会产生n-1个划分点，选择信息增益最大的作为最优划分点\n",
    "    n = len(data)\n",
    "    # 从小到大排序\n",
    "    data_a_value = sorted(data[a].values)\n",
    "    # 原始数据集的信息熵Ent(D)\n",
    "    ent = cal_information_entropy(data)\n",
    "    select_points = []\n",
    "    for i in range(n - 1):\n",
    "        # 两个值中间取值为划分点\n",
    "        val = (data_a_value[i] + data_a_value[i + 1]) / 2\n",
    "        data_left = data.loc[data[a] < val]\n",
    "        data_right = data.loc[data[a] > val]\n",
    "        ent_left = cal_information_entropy(data_left)\n",
    "        ent_right = cal_information_entropy(data_right)\n",
    "        result = ent - len(data_left) / n * ent_left - len(data_right) / n * ent_right\n",
    "        select_points.append([val, result])\n",
    "    # 按照信息增益排序\n",
    "    select_points.sort(key=lambda x: x[1], reverse=True)\n",
    "    # 返回信息增益最大的点, 以及对应的信息增益\n",
    "    return select_points[0][0], select_points[0][1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 获取最佳划分特征\n",
    "def get_best_feature(data):\n",
    "    features = data.columns[:-1]\n",
    "    res = {}\n",
    "    for a in features:\n",
    "        if a in continuous_features:\n",
    "            temp_val, temp = cal_information_gain_continuous(data, a)\n",
    "            res[a] = [temp_val, temp]\n",
    "        else:\n",
    "            temp = cal_information_gain(data, a)\n",
    "            res[a] = [-1, temp]  #离散值没有划分点，用-1代替\n",
    "\n",
    "    res = sorted(res.items(), key=lambda x: x[1][1], reverse=True)\n",
    "    return res[0][0], res[0][1][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 将数据转化为（属性值：数据）的元组形式返回，并删除之前的特征列，只针对离散数据\n",
    "def drop_exist_feature(data, best_feature):\n",
    "    attr = pd.unique(data[best_feature])\n",
    "    new_data = [(nd, data[data[best_feature] == nd]) for nd in attr]\n",
    "    new_data = [(n[0], n[1].drop([best_feature], axis=1)) for n in new_data]\n",
    "    return new_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 创建决策树\n",
    "def create_tree(data):\n",
    "    if len(data) == 0:\n",
    "        # 没有数据，设置为 examples 中最普遍的数据值\n",
    "        return most_label\n",
    "    data_label = data.iloc[:, -1]\n",
    "    # 只有一类\n",
    "    if len(data_label.value_counts()) == 1:\n",
    "        return data_label.values[0]\n",
    "    # 所有数据的特征值一样，选样本最多的类作为分类结果\n",
    "    if all(len(data[i].value_counts()) == 1 for i in data.iloc[:, :-1].columns):\n",
    "        return get_most_label(data)\n",
    "    # 根据信息增益得到的最优划分特征\n",
    "    best_feature, best_feature_val = get_best_feature(data)\n",
    "    # 连续值\n",
    "    if best_feature in continuous_features:\n",
    "        node_name = best_feature + '<' + str(best_feature_val)\n",
    "        # 用字典形式存储决策树\n",
    "        tree = {node_name: {}}\n",
    "        tree[node_name]['是'] = create_tree(data.loc[data[best_feature] < best_feature_val])\n",
    "        tree[node_name]['否'] = create_tree(data.loc[data[best_feature] > best_feature_val])\n",
    "    else:\n",
    "        tree = {best_feature: {}}\n",
    "        # 当前数据下最佳特征的取值\n",
    "        exist_vals = pd.unique(data[best_feature])\n",
    "        # 如果特征的取值相比于原来的少了\n",
    "        if len(exist_vals) != len(column_count[best_feature]):\n",
    "            # 少的那些特征\n",
    "            no_exist_attr = set(column_count[best_feature]) - set(exist_vals)\n",
    "            for no_feat in no_exist_attr:\n",
    "                # 缺失的特征分类为当前类别最多的\n",
    "                tree[best_feature][no_feat] = get_most_label(data)\n",
    "        # 根据特征值的不同递归创建决策树\n",
    "        for item in drop_exist_feature(data, best_feature):\n",
    "            tree[best_feature][item[0]] = create_tree(item[1])\n",
    "    return tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#根据创建的决策树进行分类\n",
    "def predict(tree, predict_data):\n",
    "    first_feature = list(tree.keys())[0]\n",
    "    if (feature_name := first_feature.split('<')[0]) in continuous_features:\n",
    "        second_dict = tree[first_feature]\n",
    "        val = float(first_feature.split('<')[-1])\n",
    "        input_first = predict_data.get(feature_name)\n",
    "        if input_first < val:\n",
    "            input_value = second_dict['是']\n",
    "        else:\n",
    "            input_value = second_dict['否']\n",
    "    else:\n",
    "        second_dict = tree[first_feature]\n",
    "        input_first = predict_data.get(first_feature)\n",
    "        input_value = second_dict[input_first]\n",
    "    # 判断分支还是不是字典\n",
    "    if isinstance(input_value, dict):\n",
    "        class_label = predict(input_value, predict_data)\n",
    "    else:\n",
    "        class_label = input_value\n",
    "    return class_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usefulCount<5.0': {'是': {'usefulCount<3.0': {'是': {'usefulCount<2.0': {'是': {'usefulCount<0.0': {'是': 5, '否': {'usefulCount<1.0': {'是': 5, '否': 5}}}}, '否': 5}}, '否': {'usefulCount<4.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<7.0': {'是': {'usefulCount<6.0': {'是': 5, '否': 5}}, '否': {'usefulCount<8.0': {'是': 5, '否': {'usefulCount<9.0': {'是': 5, '否': {'usefulCount<12.0': {'是': {'usefulCount<10.0': {'是': 5, '否': {'usefulCount<11.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<14.0': {'是': {'usefulCount<13.0': {'是': 5, '否': 5}}, '否': {'usefulCount<15.0': {'是': 5, '否': {'usefulCount<17.0': {'是': {'usefulCount<16.0': {'是': 5, '否': 5}}, '否': {'usefulCount<18.0': {'是': 5, '否': {'usefulCount<22.0': {'是': {'usefulCount<20.0': {'是': {'usefulCount<19.0': {'是': 5, '否': 5}}, '否': {'usefulCount<21.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<23.0': {'是': 5, '否': {'usefulCount<25.0': {'是': {'usefulCount<24.0': {'是': 5, '否': 5}}, '否': {'usefulCount<28.0': {'是': {'usefulCount<27.0': {'是': {'usefulCount<26.0': {'是': 5, '否': 5}}, '否': 5}}, '否': {'usefulCount<35.0': {'是': {'usefulCount<33.0': {'是': {'usefulCount<32.0': {'是': {'usefulCount<31.0': {'是': {'usefulCount<29.0': {'是': 5, '否': {'usefulCount<30.0': {'是': 5, '否': 5}}}}, '否': 5}}, '否': 5}}, '否': {'usefulCount<34.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<36.0': {'是': 5, '否': {'usefulCount<41.0': {'是': {'usefulCount<39.0': {'是': {'usefulCount<38.0': {'是': {'usefulCount<37.0': {'是': 5, '否': 5}}, '否': 5}}, '否': {'usefulCount<40.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<43.0': {'是': {'usefulCount<42.0': {'是': 5, '否': 5}}, '否': {'usefulCount<55.0': {'是': {'usefulCount<45.0': {'是': {'usefulCount<44.0': {'是': 5, '否': 5}}, '否': {'usefulCount<48.0': {'是': {'usefulCount<46.0': {'是': 5, '否': {'usefulCount<47.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<50.0': {'是': {'usefulCount<49.0': {'是': 5, '否': 5}}, '否': {'usefulCount<54.0': {'是': {'usefulCount<51.0': {'是': 5, '否': {'usefulCount<53.0': {'是': {'usefulCount<52.0': {'是': 5, '否': 5}}, '否': 5}}}}, '否': 5}}}}}}}}, '否': {'usefulCount<65.0': {'是': {'usefulCount<57.0': {'是': {'usefulCount<56.0': {'是': 5, '否': 5}}, '否': {'usefulCount<59.0': {'是': {'usefulCount<58.0': {'是': 5, '否': 5}}, '否': {'usefulCount<61.0': {'是': {'usefulCount<60.0': {'是': 5, '否': 5}}, '否': {'usefulCount<62.0': {'是': 5, '否': {'usefulCount<64.0': {'是': {'usefulCount<63.0': {'是': 5, '否': 5}}, '否': 5}}}}}}}}}}, '否': {'usefulCount<69.0': {'是': {'usefulCount<67.0': {'是': {'usefulCount<66.0': {'是': 5, '否': 5}}, '否': {'usefulCount<68.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<75.0': {'是': {'usefulCount<70.0': {'是': 5, '否': {'usefulCount<73.0': {'是': {'usefulCount<72.0': {'是': {'usefulCount<71.0': {'是': 5, '否': 5}}, '否': 5}}, '否': {'usefulCount<74.0': {'是': 5, '否': 5}}}}}}, '否': {'usefulCount<85.0': {'是': {'usefulCount<82.0': {'是': {'usefulCount<79.0': {'是': {'usefulCount<77.0': {'是': {'usefulCount<76.0': {'是': 5, '否': 5}}, '否': {'usefulCount<78.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<81.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<84.0': {'是': {'usefulCount<83.0': {'是': 5, '否': 5}}, '否': 5}}}}, '否': {'usefulCount<102.0': {'是': {'usefulCount<91.0': {'是': {'usefulCount<89.0': {'是': {'usefulCount<87.0': {'是': {'usefulCount<86.0': {'是': 5, '否': 5}}, '否': {'usefulCount<88.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<90.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<93.0': {'是': {'usefulCount<92.0': {'是': 5, '否': 5}}, '否': {'usefulCount<96.0': {'是': {'usefulCount<95.0': {'是': {'usefulCount<94.0': {'是': 5, '否': 5}}, '否': 5}}, '否': {'usefulCount<101.0': {'是': {'usefulCount<98.0': {'是': 5, '否': 5}}, '否': 5}}}}}}}}, '否': {'usefulCount<113.0': {'是': {'usefulCount<105.0': {'是': {'usefulCount<104.0': {'是': 5, '否': 5}}, '否': {'usefulCount<109.0': {'是': {'usefulCount<108.0': {'是': {'usefulCount<107.0': {'是': 5, '否': 5}}, '否': 5}}, '否': 5}}}}, '否': {'usefulCount<157.0': {'是': {'usefulCount<118.0': {'是': {'usefulCount<114.0': {'是': 5, '否': {'usefulCount<116.0': {'是': {'usefulCount<115.0': {'是': 5, '否': 5}}, '否': {'usefulCount<117.0': {'是': 5, '否': 5}}}}}}, '否': {'usefulCount<126.0': {'是': {'usefulCount<121.0': {'是': {'usefulCount<119.0': {'是': 5, '否': {'usefulCount<120.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<123.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<140.0': {'是': {'usefulCount<135.0': {'是': {'usefulCount<131.0': {'是': {'usefulCount<128.0': {'是': 4, '否': 5}}, '否': 5}}, '否': {'usefulCount<137.0': {'是': 4, '否': {'usefulCount<138.5': {'是': 5, '否': 4}}}}}}, '否': {'usefulCount<148.0': {'是': {'usefulCount<142.0': {'是': {'usefulCount<141.0': {'是': 5, '否': 5}}, '否': {'usefulCount<146.0': {'是': 5, '否': 5}}}}, '否': {'usefulCount<155.0': {'是': {'usefulCount<149.0': {'是': 5, '否': 5}}, '否': 5}}}}}}}}}}, '否': {'usefulCount<190.0': {'是': {'usefulCount<177.0': {'是': {'usefulCount<159.0': {'是': 2, '否': {'usefulCount<175.0': {'是': {'sideEffects': {1: 5, 4: {'usefulCount<167.5': {'是': 5, '否': {'usefulCount<169.5': {'是': 4, '否': 5}}}}, 2: 5, 5: 5, 3: 5}}, '否': 5}}}}, '否': {'usefulCount<178.5': {'是': 4, '否': 5}}}}, '否': {'usefulCount<308.0': {'是': {'sideEffects': {5: {'usefulCount<214.0': {'是': {'usefulCount<209.5': {'是': 5, '否': 4}}, '否': 5}}, 3: {'usefulCount<260.0': {'是': {'usefulCount<213.5': {'是': {'usefulCount<198.0': {'是': 5, '否': 3}}, '否': 5}}, '否': 4}}, 4: {'usefulCount<197.5': {'是': {'usefulCount<193.0': {'是': 3, '否': {'usefulCount<196.0': {'是': 5, '否': 1}}}}, '否': {'usefulCount<272.5': {'是': {'usefulCount<207.0': {'是': 5, '否': {'usefulCount<211.0': {'是': 4, '否': 5}}}}, '否': {'usefulCount<287.0': {'是': 3, '否': 5}}}}}}, 2: {'usefulCount<215.5': {'是': 4, '否': {'usefulCount<235.5': {'是': 5, '否': {'usefulCount<264.0': {'是': 4, '否': 5}}}}}}, 1: 5}}, '否': {'usefulCount<455.0': {'是': 5, '否': {'usefulCount<514.5': {'是': 1, '否': 5}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "decision_tree = create_tree(train_data)\n",
    "print(decision_tree)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def convert_data_for_predict(data: pd.Series) -> dict:\n",
    "    drop_data = data.drop(labels=['recordId', 'drugName', 'condition', 'reviewComment', 'date', 'rating'])\n",
    "    drop_data['sideEffects'] = convert_effect_to_int(drop_data['sideEffects'])\n",
    "    data_dict = drop_data.to_dict()\n",
    "\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      recordId                 drugName                          condition  \\\n",
      "0       219597  Microgestin Fe 1.5 / 30                      Birth Control   \n",
      "1       134044               Prednisone                  Cluster Headaches   \n",
      "2        68176                   Plan B            Emergency Contraception   \n",
      "3       200538              Varenicline                  Smoking Cessation   \n",
      "4        46409                Modafinil                         Narcolepsy   \n",
      "...        ...                      ...                                ...   \n",
      "1793    132278                   Ativan                           Insomnia   \n",
      "1794    126842             Erythromycin  Upper Respiratory Tract Infection   \n",
      "1795     68153                   Plan B            Emergency Contraception   \n",
      "1796    126865                 Dilaudid                               Pain   \n",
      "1797     40841               Leuprolide                      Endometriosis   \n",
      "\n",
      "                                          reviewComment       date  \\\n",
      "0     \"I was on Microgestin Fe 1/20 for three months...  10-Sep-17   \n",
      "1     \"Have had clusters for 45 years, remember the ...  29-Aug-17   \n",
      "2     \"On June 6th 2015 I took plan B 4 HOURS after ...   6-Jul-15   \n",
      "3     \"I tried Chantix for a period of 2 months.  My...   7-Jul-11   \n",
      "4     \"I was diagnosed with Sleep Apnea, for that I ...   1-Oct-09   \n",
      "...                                                 ...        ...   \n",
      "1793  \"I was given Ativan for occasional use. I try ...   9-Aug-14   \n",
      "1794  \"This antibiotic is the best, hands down.  The...  26-Mar-16   \n",
      "1795  \"I took this pill on June 16th 2015. I was rea...  12-Aug-15   \n",
      "1796  \"I developed severe pancreatitis and hepatitis...   2-Feb-10   \n",
      "1797  \"lupron is not for everyone! I must admit I wa...  26-Aug-15   \n",
      "\n",
      "      usefulCount                    sideEffects  rating  \n",
      "0               1            Severe Side Effects       5  \n",
      "1               0          Moderate Side Effects       5  \n",
      "2              13              Mild Side Effects       5  \n",
      "3               7              Mild Side Effects       5  \n",
      "4              11          Moderate Side Effects       5  \n",
      "...           ...                            ...     ...  \n",
      "1793          176          Moderate Side Effects       5  \n",
      "1794            8            Severe Side Effects       5  \n",
      "1795            2  Extremely Severe Side Effects       5  \n",
      "1796           58              Mild Side Effects       5  \n",
      "1797           17          Moderate Side Effects       5  \n",
      "\n",
      "[1798 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# 测试集测试\n",
    "test_path = '../决策树数据集/testing.csv'\n",
    "test_data = pd.read_csv(test_path)\n",
    "test_data['rating'] = test_data.apply(lambda data: predict(decision_tree, convert_data_for_predict(data)), axis=1)\n",
    "print(test_data)\n",
    "\n",
    "# 存储到 testing_output.csv 中\n",
    "test_output_path = '../决策树数据集/testing_output.csv'\n",
    "test_data.to_csv(test_output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro_F1=0.493744787322769\n",
      "Macro_F1=0.13221663874930206\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 使用 micro 和 macro f1 来进行验证\n",
    "valid_path = '../决策树数据集/validation.csv'\n",
    "valid_data = pd.read_csv(valid_path)\n",
    "true_labels = valid_data['rating'].copy()\n",
    "predict_labels = valid_data.apply(lambda data : predict(decision_tree, convert_data_for_predict(data)), axis=1)\n",
    "micro_score = metrics.f1_score(true_labels, predict_labels, average='micro')\n",
    "macro_score = metrics.f1_score(true_labels, predict_labels, average='macro')\n",
    "print(\"Micro_F1=\" + str(micro_score))\n",
    "print(\"Macro_F1=\" + str(macro_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}