# Review

1. 强化学习
2. 降维和优化
3. 决策树
4. 强化学习
5. KNN、SVM
6. 神经元和感知机：Delta 规则
7. PCA 和 LDA
8. 梯度下降：牛顿迭代、最小二乘
9. 强化学习：给个例子，怎么构造值函数
10. KNN 算法流程、核心步骤、关键优缺点
11. ID3 构造决策树
12. 召回率等评价指标

![20230406164921](https://img-bed-1309306776.cos.ap-shanghai.myqcloud.com/img/20230406164921.png)

## 神经元与感知机

### 感知机学习规则

1. 权值初始化
2. 输入样本对
3. 计算输出
4. 根据感知机学习规则调整权重
   1. 期望输出和实际输出相同，不改变权值（w0、w1、w2 等）
   2. 实际输出为-1，期望输出为+1，则增加 2cXi
   3. 实际输出为+1，期望输出为-1，则减少 2cXi
5. 返回到步骤2输入下一个样本，直到所有的样本的实际输出与期望输出相同

![感知机学习规则](https://img-bed-1309306776.cos.ap-shanghai.myqcloud.com/img/20230410204013.png)

![感知机学习规则](https://img-bed-1309306776.cos.ap-shanghai.myqcloud.com/img/20230410203715.png)

### 线性可分概念

D0 和 D1 是 n 维欧氏空间中的两个点集（点的集合）。如果存在 n 维向量 w 和实数 b，使得所有属于 D0 的点 xi 都有 wxi+b>0，而对于所有属于 D1 的点 xj 则有 wxj+b<0。则我们称 D0 和 D1 线性可分。

> 通俗来说就是可以通过一条直线将样本分成两类

## 神经元网络

### 多层感知机、梯度下降如何修改导数

![Delta规则](https://img-bed-1309306776.cos.ap-shanghai.myqcloud.com/img/20230410205247.png)

![Delta规则](https://img-bed-1309306776.cos.ap-shanghai.myqcloud.com/img/20230410205913.png)

## 纬度约减

### PCA

1. 获得均值
2. 计算协方差矩阵
3. 获得前 n 大的特征值特征向量
4. 作为行向量映射即可 Y=PX

### LDA

思想：投影后类内方差最小，类间方差最大

![LDA](https://img-bed-1309306776.cos.ap-shanghai.myqcloud.com/img/20230410210826.png)

## 优化和搜索

### 牛顿法

### 最小二乘优化

## 强化学习

### 计算值函数

### 书上例子

## 概率与学习

### KNN

对于测试数据：

1. 计算和训练数据的距离
2. 找到距离最近的 k 个数据
3. 选取这 k 个数据中比较多的类别作为该测试数据的类别（k 一般选奇数防止平局）
4. 有监督的学习方法

## 树学习

### ID3 决策树

1. 熵和信息增益

![ID3算法](https://img-bed-1309306776.cos.ap-shanghai.myqcloud.com/img/20230411195352.png)

![ID3算法](https://img-bed-1309306776.cos.ap-shanghai.myqcloud.com/img/20230411195410.png)

## 无监督学习

## 支持向量机
