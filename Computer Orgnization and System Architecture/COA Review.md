# COA Review

[toc]

## 1 计算机系统概述

### What is computer

​	计算机是指<span style='color: red'>**通用电子数字计算机**</span>（general-purpose electronic digital computer）

* **通用**：不是一种专用设备
	* 所有计算机在给予足够时间和容量存储器的条件下，都可以完成同样的计算
	* 当希望完成新的计算时，不需要对计算机重新设计
* **电子**（非机械）：采用电子元器件
* **数字**（非模拟）：信息采用数字化的形式表示

***



### Organization and Architecture

1. <span style='color: orange'>**组织**</span>（Organization）：对编程人员不可以见
	* 操作单元及其相互连接
	* 包括：控制信号，存储技术，$\dots$
		* 例如：实现乘法是通过硬件单元还是重复加法（how to implement multiplication，编程人员不需要知道如何实现，只需要知道有加法这个东西，封装的实现就是**组织**）
2. <span style='color: orange'>**结构**</span>（Architecture）：对编程人员可见
	* 直接影响程序逻辑执行的属性
	* 包括：指令集，表示数据类型的位数，$\dots$
		* 例如：是否有乘法指令（是否有某种功能的接口，编程人员需要知道有这种接口才可以调用这种功能，这种就是**结构**）

***



### History of computer

#### 第一代 真空管（1946-1957）

1. ENIAC（1946-1955）：第一台通用计算机，十进制，手动编程

2. ABC（1937）：世界上第一台计算机，不可编程

3. EDVAC：<span style='color: red'>**冯·诺依曼结构**</span>

	>  冯诺依曼结构
	>
	> 又称为“普林斯顿结构"
	>
	> 三个**基本原则**：
	>
	> 1. 二进制
	> 2. 存储程序
	> 3. 5个组成部分
	> 	* 主存储器（存储单元）：地址和存储的内容
	> 	* 算术逻辑单元（处理单元）：执行信息的实际处理
	> 	* 程序控制单元（控制单元）：指挥信息的处理
	> 	* 输入设备：将信息送入计算机中
	> 	* 输出设备：将处理结果以某种形式显示在计算机外



#### 第二代 晶体管（1958-1964）



#### 第三代及后续几代：集成电路（1965-现在）

思想：

* 将整个电路安装在很小的硅片上，而不是用分立元件搭成的等价电路

* 这些晶体管可以通过金属化过程相互连接，以形成电路

***



### Moore‘s Law

<span style='color: red'>**摩尔定律**</span>：单芯片上所能包含的晶体管数量每年翻一番，1970年起减慢为每18个月翻一番

影响：

1. 更小的尺寸带来更多灵活性和可能性
2. 由于单个芯片的成本几乎不变，计算机逻辑电路和存储电路的成本显著下降
3. 减小了对电能消耗和冷却的要求
4. 集成电路上的内部连接比焊接更可靠，芯片间的连接更少

***



### Computer Performance

计算机的关键参数之一：性能，成本，尺寸，安全性，可靠性，能耗

性能评价标准：

* CPU：速度
* 存储器：速度，容量
* I/O：速度，容量
* $\dots$

> **计算机设计的主要目标是：提高CPU性能**

***



### CPU Performance

#### 系统时钟

1. <span style='color: red'>**时钟频率**</span> / 时钟速度（单位：Hz）：计算机在单位时间内（例如1秒钟）执行的最基本操作的次数
2. <span style='color: red'>**时钟周期**</span> / 周期时间（单位：s）：执行每次最基本操作的时间
	* 时钟滴答（有时也称为“**时钟周期**”）：CPU中用于同步执行最基本操作的单个单子脉冲
	* 因此，周期时间即为两个电子脉冲之间的时间

#### 指令执行

1. 处理器由时钟驱动，时钟具有固定的频率 $f$，或等价为固定的时钟周期 $t$

2. 如果用 $CPI_i$ 来表示执行指定类型 $i$ 指令所需要的周期数，用 $I_i$ 表示在某一给定程序中所执行的 $i$ 类指令的条数，则可以计算整个的 $CPI$ 如下：
	$$
	CPI = \frac{\sum_{i=1}^n(CPI_i \times I_i)}{I_c},  I_c = \sum_{i=1}^n I_i
	$$

	> $CPI$：Cycle per Instruction, 执行每条指令平均需要的时钟周期

3. 执行一个给定程序的处理时间表示为：
	$$
	T = I_c \times CPI \times t \\
	T = I_c \times [p + (m \times k)] \times t
	$$

	> $p$：译码和执行指令的时间
	>
	> $m$：存储器访问次数
	>
	> $k$：存储器周期时间和处理器周期时间之比
	>
	> $(m \times k) \times t$：在处理器和存储器之间传输数据
	>
	> $t$：时钟周期

![](https://s2.loli.net/2022/01/05/uB5cEFsZYbnyO6C.jpg)



* 每秒百万条指令（MIPS）：
	$$
	MIPS = \frac{I_c}{T \times 10^6} = \frac{f}{CPI \times 10^6}
	$$

* 每秒百万条浮点操作（MFLOPS）：
	$$
	MFLOPS = \frac{N_{floating-point\ op}}{T \times 10^6}
	$$

#### 基准程序

1. 使用一系列基准程序来测量系统的性能
2. 平均结果
	* 算术平均值：$R_A = \frac{1}{m} \sum_{i=1}^n R_i$
	* 调和平均值：$R_H = \frac{m}{\sum_{i=1}^m \frac{1}{R_i}}$



## 2 计算机的顶层视图

> 冯诺依曼结构：存储单元，处理单元，控制单元，输入，输出

### Computer Top-Level Structure

![](https://s2.loli.net/2022/01/05/SmqGyjigoExI3fz.png)

![](https://s2.loli.net/2022/01/05/OnptjymW9KikMXF.png)

***



### How Computer Works

1. 指令和数据存储在单个读写存储器中

2. 主存中的内容按位置访问，**无需考虑其中包含的类型**

	> 位置：地址，存储的内容可以是数据也可以是指令也可以是地址

3. CPU从一条指令到下一条指令以**顺序**方式执行（除非明确修改）

4. I/O模块与CPU、主存交换计算机系统外部的数据

	> 冯·诺依曼结构中的输入输出指的就是I/O模块，而不是外部设备

***



### CPU

1. CPU从一条指令到下一条指令以顺序方式执行（除非明确修改）
2. 指令和数据存储在单个读写存储器中
3. 主存中的内容按位置访问，无需考虑其中包含的类型



#### Q1：CPU的频率能不能无限提高

1. 理论限制
	* mos管开关、脉冲通过门电路需要时间
	* 为了信号同步，每个脉冲信号需要持续一定的时间
	* $\dots$
2. 制造限制
	* 芯片面积越来越大，导致连线延迟越来越大，需要保证信号在设计指定时钟周期内从芯片的一角到达另一角
	* 频率越高（即mos管的开关频率也越高）会导致开关损耗也越高，cpu会费电和散热高
3. 解决：指令流水线，控制器，多核等



#### Q2：内存墙的存在

主存和CPU之间传输数据的速度跟不上CPU处理数据的速度（CPU发展速度远远快与主存发展的速度）

解决方法：采用高速缓存（Cache）

1. 添加一级或多级缓存以减少存储器访问频率并提高数据传输速率
2. 增大总线的数据宽度，来增加每次所能取出的位数



#### Q3：CPU等待I/O传输数据

CPU在等待I/O设备时保持空闲

解决方法：<span style='color: red'>**中断**</span>：其他模块（例如I/O）可以中断正常处理顺序的机制。将中断周期加入指令周期

***



### Memory

1. 指令和数据存储在单个读写存储器中
2. 主存中的内容按位置访问，无需考虑其中包含的类型



#### Q4：兼顾存储容量、速度和陈本

* 约束

	* 容量：越大越好
	* 速度：跟上存储器处理数据的速度
	* 成本：相对于其他组件合理

* 约束之间的关系

	* 更短的访问时间，更高的每bit成本

* 解决方法：层次式存储结构（存储金字塔）

	* 需求：
		* 大容量数据存储
		* 高速性能
	* 解决方案：使用存储器层次结构而不是依赖单个存储器组件

	![](https://s2.loli.net/2022/01/05/Jvq1Pi7WMhnrHyD.png)

***



### I/O

与CPU和内存交换从外部来源收集的数据（注意外部设备不能算是I/O中的东西，I/O指的是I/O模块，负责控制和传输）

#### Q5：I/O设备传输速率差异大

I/O性能跟不上CPU速度的提升

解决方法：采用缓冲区和改进I/O操作技术

***



### Bus（总线）

总线时连接两个或多个设备的通信道路



#### Q6：计算机部件互联复杂

解决方案：采用总线

数据传输类型

* 控制线：控制数据线和地址线的访问和实用
* 地址线：指定数据总线和地址I/O端口上数据的来源或去向
* 数据线：在系统模块之间传送数据

***



## 3 数据的机器级表示

### 信息的二进制编码

在冯·诺依曼结构中，所有信息（指令和数据）都采用二进制编码

* **编码**：用少量简单的基本符号对复杂多样的信息进行一定规律的组合
* <span style='color: red'>**采用二进制的原因**</span>
	* 多种物理器件可以表示两种稳定的状态，用于表示二进制中的$0$ 和 $1$ 
	* 二进制的编码和运算规则简单
	* $0$ 和 $1$ 可以对应逻辑命题中的 “真” 和 “假”
* $K$ 位的二进制编码**至多**表示 $2^K$ 个不同的值（无论是什么类型的数据都遵循这个规则）

***



### 整数的二进制表示

1. 无符号整数
2. 有符号整数：原码，反码，移码，补码
	* 原码、反码、移码在进行加法运算时都会造成不必要的硬件需求，因此目前计算机中普遍使用补码
	* 二进制补码的运算
	* 二进制 - 十进制的转换



#### 补码表示法

相比原码表示法的优势：无论同号还是异号都可以直接相加

表示：正数与原码相同，负数在对应原码的基础上**“取反加一”**

1. 000...000 ~ 011...111：表示的值不变，与原码相同

2. 100...000 ~ 111...111：表示的值由原来的$2^{k-1} \sim 2^{k} - 1$ 变为 $2^{k-1} \sim -1$ （平移）

	> 真值由原来的无符号数对应的真挚减去 $2^k$，取反加一的由来



#### 补码的真值

$$
[X]_c = X_nX_{n-1} \dots X_2X_1 \\
X = -X_n \times 2^{n-1} + X_{n-1} \times2^{n-2} + \dots + X_2 \times 2^1 + X_1 \times 2^0
$$

值的范围：$-2^{n-1} \le X \le 2^{n-1} - 1$

***



### 浮点数的二进制数表示

1. 实数表示

2. **定点表示法**表示值的范围是有限制的

3. 科学计数法：
	$$
	\pm S \times B^E
	$$

	> $\pm$：符号，正或负
	>
	> $S$：尾数/有效值
	>
	> $B$：基/底，对所有数都是相同的，不需要存储的（隐含的）
	>
	> $E$：阶码/指数



#### 规格化数

**规格化表示**：
$$
\pm 1.bbb\dots b \times 2^E
$$

* 符号总是位于字的第一位

* 尾数（$S$）的第 $1$ 位总是 $1$，不需要存入尾数字段中（默认省略）

* 阶码（$E$）的真实值加上 $127$ 后，再存入阶码字段中（移码）

	> 假设阶码位数为$e$，则偏移量计算如下：
	> $$
	> bias = 2^{e-1} - 1
	> $$

* 底（$B$）默认为2



**值的范围（未引入非规格化数的情况下）**

* 介于 $-(2 - 2^{-23}) \times 2^{128}$  和 $-2^{-127}$ 之间的负数
* 介于 $2^{-127}$ 和 $(2 - 2^{-23}) \times 2^{128}$ 之间的正数

![](https://s2.loli.net/2022/01/05/KBuJL6dFEGQa2xI.png)



**规格化数的变化**

对于一定长度的规格化数，表示范围和精度之间存在权衡

1. 增加阶码位数：扩大表示范围，降低表示精度
2. 增加尾数尾数：提高表示精度，减少表示范围
3. 采用更大的底：实现更大的范围，降低表示的精度



#### 非规格化数

* 处理规格化数中的下溢情况
* 当结果的阶值太小时，通过右移进行非规格化；每次右移阶值增，直到阶值落在可表示范围内

![](https://s2.loli.net/2022/01/05/CAUHGnoa5W1ih89.png)



#### IEEE754标准

![](https://s2.loli.net/2022/01/05/phPBFnNWGm3CUt2.png)

![](https://s2.loli.net/2022/01/05/YoKFkXRCP6vMeaU.png)

***



### 二进制编码表示的十进制数表示

* 浮点运算的问题：精度限制、转换成本高
* 应用需要：长数字串的计算
* 解决方法：用 $4$ 位<span style='color: red'>**二进制编码十进制**</span>（BCD）表示 $0, 1, 2, \dots , 9$ 直接计算



#### NBCD码

1. $0 \sim 9$：$0000 \sim 1001$
2. 符号：使用四个最高有效位
	1. 正：$1100/0$
	2. 负：$1101/1$

***



## 4 数据校验码

### 差错（Error）

* 数据在计算机内部进行计算 、 存取和传送过程中 由于元器件故障
	或噪音干扰等原因 会出现差错
* 以存储为例
	* 硬故障（hard failure）： 永久性的物理故障，以至于受影响的存储单元不能可靠地存储数据，成为固定的 $1$ 或 $0$ 故障或者在 $0$ 和 $1$ 之间不稳定地跳变
		* 由恶劣的环境 、制造缺陷和旧损引起
	* 软故障 （soft error）：随机非破坏性事件，它改变了某个或某些存储单元的内容 但没有损坏机器
		* 由电源问题或 α 粒子引起
* 解决方案
	* 从计算机硬件可靠性入手，在电路 、电源 、布线等方面采取必要的措施，提高计算机的抗干扰能力
	* 采取数据检错和校正措施，自动发现并纠正错误

***



### 纠错（Error Correction）

* 基本思想：存储额外的信息以进行检错和校正

* 处理过程

	* 数据输入：使用函数 $f$ 在 $M$ 位数据 $D$ 上生成 $K$ 位的校验码 $C$

	* 数据输出：使用函数 $f$ 在 $M$ 位数据 $D'$ 上生成新的 $K$ 位校验码 $C''$，并与取出的 $K$ 位校验码 $C'$ 进行比较

		> 注意这里的 $C$ 不一定等于 $C'$，因为在数据存储的过程中校验码也有可能变化，所以我们进行比较的其实是**取出后**的校验码和将取出后的数据经过计算得到的校验码来判断是否有出错。
		>
		> 我们可以考虑一种特殊情况：如果在存储过程中数据和校验码同时出错，且数据出错后计算得到的校验码刚好是校验码出错后的结果，那么这种纠错就会失去作用。
		>
		> 不过幸运的是，在这里我们都假设只有一位会出错（无论数据还是校验码）。

		* 没有检测到差错：使用数据 $D'$ （$D'$ 可能不等于 $D$）
		* 检测到差错并且可以校正：校正数据 $D'$ 来生成数据 $D''$，并用数据 $D''$
		* 检测到差错但无法纠正：报告

![](https://s2.loli.net/2022/01/05/HNOhuwPBq8ML31Q.png)

***



### 奇偶校验码

**基本思想**：增加一位校验码来表示数据中 $1$ 的数量是奇数还是偶数

**处理过程**：

1. 假设数据为 $D = D_M \dots D_2D_1$
2. 数据输入（奇校验的数据加入校验码后有奇数个 $1$，偶校验相反）
	* 奇校验：$C = D_M \oplus \dots \oplus D_2 \oplus D_1 \oplus 1$
	* 偶校验：$C = D_M \oplus \dots \oplus D_2 \oplus D_1$
3. 数据输出
	* 奇校验：$C'' = D'_M \oplus \dots \oplus D'_2 \oplus D'_1 \oplus 1$
	* 偶校验：$C'' = D'_M \oplus \dots \oplus D'_2 \oplus D'_1$
4. 检错：$S = C'' \oplus C'$
	* $S = 0$：正确 / 数据中出错的位数为偶数
	* $S = 1$：数据中心出错的位数为奇数

**优点**：代价低，只需要1位额外数据，计算简单

**缺点**：

1. 不能发现出错位数为偶数的情形
2. 发现错误后不能校正



### 海明码

**基本思想**：将数据分成几组，对每一组都使用奇偶校验码进行检错

**处理过程**：

1. 将 $M$ 位数据分成 $K$ 组
2. 数据输入：为数据 $D$ 中每组生成 $1$ 位校验码，合并得到 $K$ 位校验码 $C$
3. 数据输出：为数据 $D'$ 中每组生成 $1$ 位校验码，合并得到新的 $K$ 位校验码 $C''$
4. 检错：将校验码 $C''$ 和取出的校验码 $C''$ 按位进行异或，生成 $K$ 位<span style='color: red'>**故障字（syndrome word）**</span>

**校验码长度**

> 假设最多 $1$ 位发生错误，数据的长度为 $M$，校验码长度为 $K$

可能的情况：

* 数据中有一位出现错误：$M$
* 校验码中有一位出现错误：$K$
* 没有出现错误：$1$

**校验码长度**：
$$
2^K \ge M + K + 1
$$


#### 故障字

故障字的每种取值都反映一种情形（数据出错 / 校验码出错 / 未出错）

**规则**：

1. 全都是0：没有检测到错误
2. 有且仅有1位是1：错误发生在校验码中的某一位，不需要纠正
3. 有多位为1：错误发生在数据中的某一位，将 $D'$ 中对应数据位取反即可纠正（得到$D''$）

> 将位设置在与其故障字值相同的位置

![](https://s2.loli.net/2022/01/05/L3pa76GrimFzTlb.png)



### 循环冗余校验（Cyclic Redundancy Check, CRC）

> * 适用于以流格式存储和传输大量数据
>
> * 用数学函数生成数据和校验码之间的关系

**基本思想**：

1. 假设数据有 $M$ 位，左移数据 $K$ 位（右侧补 $0$），并用 $K+1$ 位<span style='color: red'>**生成多项式**</span>除它（模 $2$ 运算）
2. 采用 $K$ 位余数作为校验码
3. 把校验码放在数据（不含补的0）后面，一同存储或传输

**校错**：

1. 如果 $M+K$ 位内容可以被生成多项式除尽，则没有检测到错误
2. 否则，发生错误



#### 模2运算

规则：有一落一，没一落零，做异或运算。



## 5 整数运算

### 算术逻辑单元（ALU）

算术逻辑单元是计算机实际完成数据算术逻辑运算的部件

1. 数据由寄存器（registers）提交给ALU，运算结果也存于寄存器
2. ALU可能根据运算结果设置一些标志（Flags），标志值也保存在处理器内的寄存器中
3. 控制器（Control unit）提供控制ALU操作和数据传入送出ALU的信号

***



### 加法

#### 全加器

1. 与门延迟：1ty
2. 或门延迟：1ty
3. 异或门延迟：3ty

**基本思想**：第 $i$ 位加法
$$
S_i = X_i \oplus Y_i \oplus C_{i-1} \\
C_i = X_iC_{i-1} + Y_iC_{i-1} + X_iY_i
$$
![](https://s2.loli.net/2022/01/05/uM783myYlLTNcUb.png)

#### 串行进位加法器

**延迟**：
$$
C_n = 2n\ ty \\
S_n = (2n+1)\ ty
$$

> 计算 $S_1$ 时，不需要等待 $C_0$，直接计算 $X_1 \oplus Y_1 \oplus C_0$，需要6ty的延迟
>
> 计算 $S_2$ 时，$C_1$ 的延迟是 2ty（按照公式），但此时 $X_2 \oplus Y_2$ 还没算完（需要3ty的延迟），所以仍然不需要等待 $C_1$，此时仍然只需要 6ty 的延迟
>
> 其余时刻，由于计算 $S_n$ 的时候需要等待 $C_{n-1}$ ，在等待过程中可以先把 $X_{n} \oplus Y_{n}$ 算好，因此只需要在 $2n-2$ 的基础上（计算 $C_{n-1}$ 的延迟）再加上异或门的时间（3ty），因此$S_n = (2n+1)\ ty$



#### 全先行进位加法器（CLA）

定义两个辅助函数：

1. $P_i = X_i + Y_i$
2. $G_i = X_iY_i$

**延迟：6ty**

> 1. 先求所有的 $P_i$ 和 $G_i$，需要 1ty（并行求）
> 2. 再求所有的 $C_n$，需要2ty。 $C_i = P_iC_{i-1} + G_i$
> 3. 再与 $X_n \oplus Y_n$ 的结果进行异或，因为前面两个的延迟和是3ty，所以 $X_n \oplus Y_n$ 也同步完成，这里直接进行异或即可



#### 部分先行加法器

思路：采用多个CLA并将其串联，取得计算时间和硬件复杂度之间的权衡。

![](https://s2.loli.net/2022/01/05/4sofz1GrdRnxO2w.png)

延迟：12ty

> 首先计算所有CLA中的 $P_i$ 和 $G_i$，需要 1ty，然后计算第一个CLA中的 $C_n$，需要2ty，同时在这 3ty 中同步计算所有CLA中的 $X_i \oplus Y_i$，然后$C_8$ 传到第二个CLA中，第二个CLA计算 $C_n$，需要 2ty，第三个同理，同时在这4ty的延迟中，第一个CLA已经计算好了 $X_i \oplus Y_i \oplus C_{i-1}$ 。然后到最后一个CLA，同理计算 $C_n$，然后计算 $X_i \oplus Y_i \oplus C_{i-1}$，同步进行的还有第二个和第三个CLA的计算 $X_i \oplus Y_i \oplus C_{i-1}$。（可以将四个CLA的计算 $X_i \oplus Y_i \oplus C_{i-1}$ 看成同步进行的）



#### overflow

$$
X_n = Y_n \land S_n \ne X_n, Y_n: overflow = X_nY_n\overline{S_n} + \overline{X_n}\overline{Y_n}S_n \\
C_n \ne C_{n-1}:overflow = C_n \oplus C_{n-1}
$$

### 减法

溢出与加法相同

![](https://s2.loli.net/2022/01/05/OPXCvVJl86ZMN27.png)



### 乘法

**计算机乘法的改进**

* 每一步都计算部分积求和结果
* 右移部分积代替左移部分积
* 若 $Y_i = 0$，只执行移位操作

**问题**：$[X \times Y]_c \ne [X]_c \times [Y]_c$



#### 布斯乘法

**推导：**

![20220105203056.png](https://s2.loli.net/2022/01/05/qrsguzwHRNIBJcT.png)

**布斯乘法**

1. 增加 $Y_0 = 0$
2. 根据 $Y_i - Y_{i+1}$，决定是否增加 $+X, -X, +0$
3. 右移部分积（**右移补充的是符号位**）
4. 重复步骤2和步骤3 $n$ 次，得到最终结果

***



### 除法

**不同情形的处理**

* 若被除数为0，除数不为0：商为0
* 若被除数不为0，除数为0：发生“除数为0”异常
* 若被除数、除数均为0，发生“除法错”异常
* 其余情况进行进一步的除法运算



**手工演算除法**

* 在被除数的左侧补充符号位，将除数的最高位与被除数的次高位对齐
* 从被除数中减去除数，若**够减**，则上商为1；若**不够减**，则上商为0
* 右移除数，重复上述步骤



**改进**

1. 右移除数编程左移余数/商
2. 余数和商放在一个长度为 $2n$ 的寄存器中



**如何判断够减**：余数是否足够大

* 如果余数和除数的符号相同：减法
* 如果余数和除数的符号不同：加法

![](https://s2.loli.net/2022/01/05/pu3fFVXKBUnaxeC.png)



#### 恢复余数除法

**步骤过程**

1. 通过在被除数前面加 $n$ 位**符号扩展**被除数，并存储在余数寄存器和商寄存器中
2. 将余数和商左移，判断是否够减
	* 如果“够”，则做减法（同号）或加法（异号），并上商为0
	* 如果“不够”，则上商为0，并恢复余数
3. 重复以上步骤
4. 如果除数和被除数不同号，则将商替换为其**相反数**（商和被除数须同号）
5. 余数存在余数寄存器中



#### 不恢复余数除法

**大致思路**：不恢复余数，只考虑减法

* 如果余数 $R_i$ 足够大： $R_{i+1} = 2R_i - Y$
* 如果余数 $R_i$ 不够大： $R_{i+1} = 2(R_i +Y) - Y = 2R_i + Y$



**步骤过程**

1. 通过在被除数前面加 $n$ 位**符号扩展**被除数，并存储在余数寄存器和商寄存器中
2. 如果除数和被除数符号相同，则做减法；否则，做加法
	* 如果余数和除数符号相同，则商 $Q_n = 1$，否则 $Q_n = 0$
3. 如果余数和除数符号相同，$R_{i+1} = 2R_i - Y$；否则，$R_{i+1} = 2R_i + Y$
	* 如果新的余数和除数符号相同，使商为1，否则，使商为0
4. 重复第三步
5. 左移商
	* 如果商是负的（被除数和除数的符号不同），商加1
6. 余数和被除数符号不同，修正余数
	* 若被除数和除数符号相同，最后余数加除数；否则，最后余数减除数



## 6 浮点数运算

### 加法和减法

**步骤过程**

1. 检查0
2. 对齐有效值（小阶对大阶）
3. 加或减有效值
4. 规格化结果

![](https://s2.loli.net/2022/01/05/MsLGdT9JltfPBmy.png)

#### 溢出

1. 阶值上溢
	* 正阶值超过可能的最大允许阶值
	* 标记为 $+ \infin$ 或者 $- \infin$
2. 阶值下溢
	* 负阶值小于可能的最小允许阶值
	* 报告为0
3. 有效值上溢
	* 同符号的两个有效值相加可能导致最高有效位的进位
	* 通过重新对齐来修补
4. 有效值下溢
	* 在有效值对齐过程中，可能有数字被移出右端最低位而丢失
	* 需要某种形式的四舍五入（保护位）



#### 原码加法

如果两个操作数有相同的符号，做加法；否则，做减法

1. 做加法：直接相加
	* 如果最高位有进位，则溢出
	* 符号和被加数（被减数）相同
2. 做减法：加第二个操作数的补数
	* 如果最高位有进位，正确（符号与被减数相同）
	* 否则，计算它的补码（符号与被减数相反）



### 乘法

* 无论哪个操作数是0，乘积即为0
* 从阶值的和中减去一个偏移量（$e = e_x + e_y - bias$）
* 有效值相乘
* 结果的规格化和舍入处理
	* 规格化可能导致阶值下溢

![](https://s2.loli.net/2022/01/05/t2KakRxJuCXZFef.png)

### 除法

* 如果除数为0，则报告出错，或将结果设置为无穷大
* 如果被除数是0，则结果是0
* 被除数的阶值减除数的阶值，加上偏移量（$e = e_x - e_y + bias$）
* 有效值相除
* 结果规格化和舍入处理

![image-20220105213331445](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220105213331445.png)

### 精度考虑

**保护位：**

* 寄存器的长度几乎总是大于有效值位长与一个隐含位之和
* 寄存器包含的这些附加位，称为**保护位**
* 保护位用0填充，用于扩充有效值的右端

**舍入**

* 对有效值操作的结果通常保存在更长的寄存器中
* 当结果转换回浮点格式时，必须要去掉多余的位
	1. 就近舍入：结果被舍入成最近的可表示的数
	2. 朝 $+ \infin$ 舍入：结果朝正无穷大方向向上舍入
	3. 朝 $-\infin$ 舍入：结果朝负无穷大方向向下舍入
	4. 朝 $0$ 舍入：结果朝 $0$ 舍入



## 7 二进制编码的十进制数运算

### 加法

相加结果如果大于10，需要再加6来进位

1. 10 ~ 15之间，不够进位，需要补6,
2. 16 ~ 19 之间，已经进位，多减了6，需要补充一个6

### 减法

> 参照补码减法，避免借位

#### 反转数字

> 参照补码的取反加一。有两种方法进行“取反”

* 按位反转，然后添加“1010”
* 添加“0110”，并按位反转

![](https://s2.loli.net/2022/01/05/TrzUGce3EfBDjgN.png)



**结果调整**

1. 如果有进位，舍弃进位，正确
2. 如果没有进位，说明不够减，则对结果按位反转之后加一，并将结果符号取反

***



## 8 内部存储器

**存储器（Memory）**由一定数量的单元构成，每个单元可以被唯一标识，每个单元都有存储一个数值的能力

* 地址：单元的唯一标识符（采用二进制）
* 地址空间：可唯一标识的单元总数
* 寻址能力：存储在每个单元中的信息的位数
	* 大多数存储器是**字节寻址**的，而执行科学计算的计算机通常是64位寻址的



### 半导体存储器

用半导体存储器作主存储器是目前的流行做法

#### 位元（memory cell）

* 半导体存储器的基本元件，用于存储1位数据

* 特性：

	* 呈现两种稳态（或半稳态）：分别表示二进制的0或1
	* 它们能够至少被写入（write）数据一次：用来设置状态
	* 它们能够被读取（read）来获得状态信息

* 操作

	![](https://s2.loli.net/2022/01/06/iLjOI6VoW3J2TNp.png)

	![](https://s2.loli.net/2022/01/06/nj1mRWQPeXKzyxD.png)



### 半导体存储器类型

|       存储器类型       |          种类          |       可擦除性       | 写机制 | 易失性 |
| :--------------------: | :--------------------: | :------------------: | :----: | :----: |
| 随机存取存储器（RAM）  |      读-写存储器       |   电可擦除，字节级   |   电   |  易失  |
|   只读存储器（ROM）    |       只读存储器       |        不可能        |  掩膜  | 非易失 |
|   可编程ROM（PROM）    |       只读存储器       |        不可能        |   电   | 非易失 |
|  可擦除PROM（EPROM）   | 主要进行读操作的存储器 | 紫外线可擦除，芯片级 |   电   | 非易失 |
| 电可擦除PROM（EEPROM） | 主要进行读操作的存储器 |   电可擦除，字节级   |   电   | 非易失 |
|       快闪存储器       | 主要进行读操作的存储器 |    电可擦除，块级    |   电   | 非易失 |



#### 随机存取存储器（RAM）

> Random-Access Memory（RAM）

**特性：**

* 可以简单快速地进行读/写操作
* <span style='color: orange'>**易失的（Volatile）**</span>

**类型：**

* 动态RAM（DRAM）：Dynamic RAM
* 静态RAM（SRAM）：Static RAM



##### DRAM

1. 在电容器上用电容充电的方式存储数据
	* 电容器中有无电荷在分别代表二进制的1与0
2. 需要周期地**充电刷新**以维护数据存储
	* 原因：电容器有漏电的自然趋势
	* 由一个阙值来确定电荷是被解释为1还是0

![](https://s2.loli.net/2022/01/06/p98gZtuS2qEmljX.png)



##### SRAM

1. 使用传统触发器、逻辑门配置来存储二进制
	* 使用与处理器相同的逻辑元件
2. 只要有电源，就可以一直维持数据

![](https://s2.loli.net/2022/01/06/GunlCVOUtdcQs7v.png)



##### DRAM与SRAM的对比

* 相同点：易失的：两者都要求电源持续供电才能保存位值
* 不同点：
	1. DRAM比SRAM具有更简单、更小的位元，但要求能支持刷新的电路
	2. DRAM比相应的SRAM密度更高，价格更低
	3. SRAM通常比DRAM快
	4. DRAM更倾向于满足大容量存储器的需求，SRAM一般用于高速缓存（Cache），DRAM用于主存



##### 高级的DRAM架构

问题：传统的DRAM芯片收到其内部架构和与处理器内存总线接口的限制

类型：

* 同步DRAM（Synchronous DRAM, SDRAM）
* 双速率SDRAM（Double-Data-Rate SDRAM, DDR SDRAM）



###### SDRAM

传统的DRAM是异步的：

* 处理器向内存提供地址和控制信号，表示内存中特定单元的一组数据应该被读出或写入DRAM
* DRAM执行各种内部功能，如激活行和列地址线的高电容，读取数据，以及通过输出缓冲将数据输出，处理器只能等待这段延迟，即存取时间
* 延时后，DRAM才写入或读取数据

> 即处理器在读取数据是不能够马上获取数据，需要一段时间的延迟之后才能够读取DRAM（主存）中的数据



**采用SDRAM**：

* SDRAM与处理器的数据交互同步与外部的时钟信号，并且以处理器/存储器总线的最高速度运行，而不需要插入等待状态
* 由于SDRAM随系统时钟及时移动数据，CPU知道数据何时准备好，控制器可以完成其它工作

![](https://s2.loli.net/2022/01/06/xHsIXTqu1wc76hy.png)



###### DDR SDRAM

* 每个时钟周期发送两次数据，一次在时钟脉冲的上升沿，一次在下降沿（原本一个时钟周期只能提供一次数据的读写）

	> 不是CPU的时钟，而是外部的时钟信号

* DDR $\rightarrow$ DDR2 $\rightarrow$ DDR3 $\rightarrow$ DDR4

	* 增加操作频率
	* 增加预取缓冲区



#### 只读存储器（ROM）

> Read-only Memory（ROM）

**特性**

* 非易失的：不要求供电来维持数据
* 可读，但不能写入新数据

**应用**

* 微程序设计，库子程序，系统程序，寒暑表

**问题**

* 无出错处理机会：如果有一位出错，整批的ROM芯片只能报废
* 用户无法写入数据：唯一的数据写入机会在出厂时完成



##### 可编程ROM（PROM）

> Programmable ROM（PROM）

**特性**

* 非易失的
* 只能被写入一次
	* 写过程使用电信号执行
	* 需要特殊设备来完成写或**编程**过程
* 与ROM的对比
	* PROM提融了灵活性和方便性
	* ROM在大批量生产领域仍然具有吸引力



#### 主要进行读操作的存储器

> Read-Mostly Memory

**特性**

* 非易失的
* 写操作与读操作相比，较为困难

**应用**

* 读操作比写操作频繁得多的场景

**类型**

* EPROM
* EEPROM
* Flash Memory



##### 光可擦除/可编程只读存储器（EPROM）

> Erasable Programmable read-only memory（EPROM）

**特性：**

* 光擦除
	* 擦除：在写操作前将封装芯片暴露在紫外线下
		* 所有的存储单元都变回相同的初始状态
		* 每次擦除需要约20分钟
	* 电写入
* 与PROM对比
	* EPROM更贵，但具有可多次改写的优点



##### 电可擦除/可编程只读存储器（EEPROM）

> Electrically erasable progammable read-only memory（EEPROM）

**特性**

* 可以随时写入而不删除之前的内容
* 只更新寻址到的一个或多个字节
* 写操作每字节需要几百微秒

**与EPROM对比**

* EEPROM更贵，且密度低，支持小容量芯片



##### 快闪存储器

> Flash Memory

**特性**

* 电可擦除：与EEPROM相同，优于EPROM
* 擦除时间为几秒：优于EPROM，不如EEPROM
* 可以在块级擦除，不能在字节级擦除：优于EPROM，不如EEPROM
* 达到与EPROM相同的密度，优于EEPROM

**与EPROM、EEPROM对比**

* 价格和功能介于EPROM和EEPROM之间



### 从位元到主存

#### 寻址单元

> Addressable Unit

* 由若干相同地址的位元组成
* 寻址模式：Byte（常用）、word



#### 存储阵列

> Memory Array

由大量寻址单元组成

![](https://s2.loli.net/2022/01/06/pvAkIn5OrQiHzJb.png)



#### 如何寻址

**地址译码器**

* 一个 $n$ 位译码器有 $2^n$ 种输出
* 当所有 $n$ 个寻址位都满足条件时，该输出为 $1$
* 任何时候，只有一个输出是 $1$，其余都是 $0$



#### 如何刷新

1. 集中式刷新（Centralized refresh）
	* 停止读写操作，并刷新每一行
	* 刷新时无法操作内存
2. 分散式刷新（Decentralized refresh）
	* 在每个存储周期中，当读写操作完成时进行刷新
	* 会增加每个存储周期的时间
3. 异步刷新（Asynchronous refresh）
	* 每一行各自以64ms间隔刷新
	* 效率高（常用）



#### 芯片

芯片引脚

#### 模块组织

1. 位扩展：地址线不变，数据线增加
	* 使用 $8$ 块 $4K \times 1\ bit$ 的芯片组成 $4K \times 8\ bit$ 的存储器
2. 字扩展：地址线增加，数据线不变
	* 使用 $4$ 个 $16K \times 8\ bit$ 的芯片组成 $64K \times 8\ bit$ 的存储器
3. 字、位同时扩展：地址线增加，数据线增加
	* 使用 $8$ 个 $16K \times 4\ bit$ 的芯片组成 $64K \times 8\ bit$ 的存储器



#### 主存

插槽：组合多个存储模块

***



## 9 高速缓冲存储器（Cache）

> Cache的基本思路：解决内存墙带来的CPU和主存协作问题
>
> * 在使用主存（相对大而慢）之余，添加一块小而快的Cache
> * Cache位于CPU和主存之间，可以集成在CPU内部或作为主板上的一个模块
> * Cache中存放了主存中的部分信息的副本

![](https://s2.loli.net/2022/01/06/LkvdqE1u3e4KTBA.png)



### Cache的工作流程

* <span style='color: orange'>**检查（check）**</span>：当CPU试图访问主存中的某个字时，首先检查这个字是否在Cache中
* 检查分两种情况处理：
	1. <span style='color: green'>**命中（Hit）**</span>：如果在Cache中，则把**这个字**传送给CPU
	2. <span style='color: blue'>**未命中（Miss）**</span>：如果不在Cache中，则将主存中包含这个字<span style='color: red'>**固定大小的块（block）**</span>读入Cache中，然后再从Cache**传送该字**给CPU



### 问题

> 1. 如何判断是命中还是未命中
> 2. 如果未命中，为什么不直接把所需要的字从内存传送到CPU
> 3. 如果未命中，为什么从内存中读入一个块而不只读入一个字
> 4. 使用Cache后需要更多的操作，为什么还可以节省时间



#### 如何判断是命中还是未命中

> 冯·诺依曼体系的设计
>
> * CPU通过<span style='color: red'>**位置**</span>对主存中的内容进行寻址，不关心存储在其中的内容

**Cache通过标记（tags）来标识其内容在主存中的对应位置**



#### 如果未命中，为什么不直接把所需要的字从内存传送到CPU

##### 程序的局部性原理

**Definition**

处理器频繁访问主存中相同位置或者相邻存储位置的现象



**类型**

1. <span style='color: red'>**时间局部性**</span>：在相对较短的时间周期内，重复访问特定的信息（也就是访问相同位置的信息）
2. <span style='color: red'>**空间局部性**</span>：在相对较短的时间周期内，访问相邻存储位置的数据
	* <span style='color: orange'>**顺序局部性**</span>：当数据被线性排列和访问时，出现的空间局部性的一种特殊情况
	* 例如：遍历一位数组中的元素



利用“时间局部性”：将未命中的数据在返回给CPU的同时存放在Cache中，以便再次访问时命中。即如果我们再访问到这个字，因为这个字已经在Cache中了，我们就可以不用访问主存，从而减少访问主存的次数



#### 如果未命中，为什么从内存中读入一个块而不只读入一个字

利用“空间局部性”：将包含所访问的字的块存储到Cache中，以便在访问相邻数据时命中



#### 使用Cache后需要更多的操作，为什么还可以节省时间

> 假设 $p$ 是命中率， $T_c$ 是Cache的访问时间，$T_M$ 是主存的访问时间

使用Cache时的平均访问时间为：
$$
T_A = p \times T_c + (1-p) \times (T_c + T_M) \\
= T_c + (1-p) \times T_M \ \ \ \ \ \ \ \ \ \ \ \ \
$$

* 命中率 $p$ 越大， $T_c$ 越小，效果越好

* 如果想要 $T_A < T_M$，必须满足
	$$
	p > \frac{T_c}{T_M}
	$$

* 难点：Cache的容量远远小于主存的容量

> 如何理解计算平均访问时间的公式？
>
> 1. 有 $p$ 的概率只需要访问Cache，$(1-p)$ 的概率需要访问Cache和主存
> 2. 每次必定会访问Cache（检查），如果不在Cache中则访问主存（$(1-p)$ 的概率）



### Cache的设计要素



#### Cache容量

扩大Cache容量带来的结果：

1. 增大了命中率 $p$
2. 增加了Cache的开销和访问时间 $T_c$



#### 映射功能（Mapping Function）

> 实现主存块到Cache行的映射
>
> 块号，块内地址
>
> 映射方式的选择会影响Cache的组织结构
>
> * 直接映射（Direct mapping）
> * 关联映射（Associative mapping）
> * 组关联映射（Set associative mapping）



##### 直接映射

将主存中的每个块映射到<span style='color: red'>**一个固定可用的**</span>Cache行中

> 假设 $i$ 是Cache行号， $j$ 是主存储器的块号， $C$ 是Cache的行数

$$
i = j\ \ mod\ \  C
$$

**标记**

* 地址中最高 $n$ 位，且满足 $n = \log_2M - log_2C$ （$M$ 是主存中块的数量）

![](https://s2.loli.net/2022/01/06/t6sf1LX5KzCRUmx.png)



**例**

> 假设Cache有4行，每行包含8个字，主存中包含128个字。访问主存的地址长度为7位，则：

* 最低的3位：块内地址（包含8个字，需要3位来的地址来表示
* 中间的2位：映射时所对应的Cache行号（Cache有4行，所以需要2位来表示行号
* 最高的2位：区分映射到同一行的不同块，记录为Cache标记（每一行有4块能够映射到（$\frac{2^4}{2^2}$），所以需要2位来进行标记）



**优点**

* 简单
* 快速映射
* 快速检查

**缺点**

* 抖动现象（Thrashing）：如果一个程序重复访问两个需要映射到同一行中且来自不同块的字，则这两个块不断地被交换到Cache中，Cache的命中率将会降低

> 适合大容量的Cache

![](https://s2.loli.net/2022/01/06/R5YrBTwAasiobOq.png)



##### 关联映射

一个主存块可以装入Cache<span style='color: red'>**任意一行**</span>



**标记**

* 地址中最高 $n$ 位，且满足：$n = \log_2M$

![](https://s2.loli.net/2022/01/06/sGcC5FWhflLeaOA.png)

**例**

> 假设Cache有4行，每行包含8个字，主存中包含128个字。访问主存的地址长度为7位，则：

* 最低的3位：块内地址
* 最高的4位：块号，记录为Cache的标记



**优点**

* 避免抖动

**缺点**

* 实现起来比较复杂
* Cache搜索代价很大，即在检查时候需要取访问Cache的每一行

> 适合容量较小的Cache



##### 组关联映射

Cache分为若干组，每一组包含相同数量的行，每个主存块被映射到<span style='color: red'>**固定组的任意一行**</span>

> 假设 $s$ 是Cache的组号， $j$ 是主存块号， $S$ 是组数

$$
s = j\ \ mod \ \ S
$$

* <span style='color: red'>**K-路**</span>组关联映射（ $K$ 代表了一组里面有多少行）

$$
K = \frac{C}{S}
$$

**标记**

* 地址中最高 $n$ 位，且满足 $n = \log_2M - \log_2S$（ $M$ 是主存块的数量）

![](https://s2.loli.net/2022/01/06/Z2FIgqW167m3YlS.png)



**例**

> 假设Cache有4行，每行包含8个字，分成2个组，主存中包含128个字。访问主存的地址长度为7位，则：

* 最低的3位：块内地址
* 中间的1位：映射时所对应的Cache中的组（2个组只需要1为地址表示）
* 最高的3位：区分映射到同一组的不同块，记录为Cache标记（每个组有8个块可以映射到，需要3位地址来表示）



**优点**

* 结合了直接映射和关联映射的优点

**缺点**

* 结合了直接映射和关联映射的缺点

> 面向不同容量的Cache做了折中



##### 三种替换方式比较

1. 如果 $K = 1$，组关联映射等同于直接映射
2. 如果 $K = C$，组关联映射等同于关联映射



**Definition（关联度）**

一个主存块映射到Cache中可能存放的位置个数被称为关联度

* 直接映射：1
* 关联映射：C
* 组关联映射：K



1. 关联度越低，命中率越低。
	* 直接映射的命中率最低，关联映射的命中率最高
2. 关联度越低，判断是否命中的时间越短
	* 直接映射的命中时间最短，关联映射的命中时间最长
3. 关联度越低，标记所占额外空间的开销越小
	* 直接映射的标记最短，关联映射的标记最长



#### 替换算法

* 一旦Cache行被占用，当新的数据块装入Cache中时，原先存放的数据块将会被替换掉。
* 对于直接映射，每个数据块都只有唯一对应的行可以放置，没有选择的机会
* 对于关联映射和组关联映射，每个数据块被允许在多个行中选择一个进行放置，就需要替换算法来决定替换哪一行中的数据块

> **替换算法通过硬件来实现**

##### 最近最少使用算法（LRU）

**假设**：最近使用过的数据块更有可能被再次使用

**策略**：替换掉在Cache中<span style='color: orange'>**最长时间未被访问**</span>的数据块

**实现**：对于2路组关联来说：

* 每行包含一个 `USE` 位
* 当同一组中的某行被**访问**时，将其 `USE` 位设为1，同时将另一行的 `USE` 位设为0
* 当将新的数据块读入该组时，替换掉 `USE` 位为0的行中的数据块

> 编程实现中，我们使用“时间戳”来记录，对于一个访问过的数据，我们将时间戳更新到当前时间，然后替换的时候替换掉`TimeStamp`最小的那一行（代表很久没有访问过，所以没有更新时间戳（什么是时间戳？wiki



##### 先进先出算法（FIFO）

**假设**：最近由主存载入Cache的数据块更有可能被使用

**策略**：替换掉在Cache中<span style='color: orange'>**停留时间最长**</span>的块

**实现**：时间片轮转法 或 环形缓冲技术

* 每行包含一个标志位
* 当同一组的某行被替换时，将其标识位设为1，同时将其<span style='color: orange'>**下一行**</span>的标识位设为0
	* 如果被**替换**的是该组的最后一行，则将该组中的第一行的标识位设为0
* 当将新的数据块读入该组时，替换掉标识位为0的行中的数据块

> Tip：注意FIFO与LRU的区别，LRU替换的是最长时间**未被访问**的行，FIFO替换的是**停留时间最长**的行，两者的结果可能是不一样的



##### 最不经常使用算法（LFU）

**假设**：访问越频繁的数据块越有可能被再次使用

**策略**：替换掉Cache中被访问次数最少的数据块

**实现**：为每一行设置计数器 `visited`

> 编程实现中，我们对Cache中的每一行加一个标志位`visited`来记录该行被访问的次数，在替换的时候，只需要遍历该组的所有行，找到该标志位最小的行，就是我们要替换的目标



##### 随机替换算法（Random）

**假设**：每个数据块被再次使用的可能性是相同的

**策略**：随机替换Cache中的数据块

**实现**：随机替换

> 随机替换算法在性能上只稍逊于使用其他替换算法



#### 写策略

> 为什么要有写策略？

主存和Cache要有**一致性**

* 当Cache中的某个数据块被替换时，需要考虑该数据块是否被修改

两种情况

* 如果没被修改，则该数据块可以直接被替换掉
* 如果被修改，则在替换该数据块之前，必须将修改后的数据块写回到主存中对应位置

##### 写直达（write through）

所有写操作都同时对Cache和主存进行

> 即对Cache进行写操作的时候，需要同步对主存进行写操作

**优点**：确保主存中的数据总是和Cache的数据一致的，总是最新的

**缺点**：产生大量的主存访问，减慢写操作

##### 写回法（write back）

* 先更新Cache中的数据，当Cache中某个数据块被替换时，如果它被修改了，才被写回主存
* 利用一个<span style='color: orange'>**脏位（dirty bit）**</span>或者使用位（use bit）来表示块是否被修改

**优点**：减少了主存的访问次数

**缺点**：部分主存数据可能不是最新的

> I/O模块存取时可能无法获得最新的数据，为解决该问题会使得电路设计更加复杂而且有可能带来性能瓶颈



#### 行大小

* 假设从行的大小为一个字开始，随着行大小的逐步增大，则Cache的命中率会增加
	* 数据块包含了更多周围的数据，每次会有更多的数据作为一个块装入Cache中
	* 利用了空间局部性
* 当行大小变得较大之后，继续增加行大小，则Cache命中率会下降
	* 当Cache容量一定的前提下，较大的行会导致Cache中的行数变少，导致装入Cache中的数据块数量减少，进而造成数据块被频繁替换
	* 每个数据块中包含的数据在主存中位置变远，被使用的可能性减小

> 行大小与命中率之间的关系较为复杂

#### Cache数目

##### 一级 vs 多级

一级

* 将Cache与处理器置于同一芯片（片内Cache）
* 减少处理器在外部总线上的活动，从而减少了执行时间

多级

* 当L1未命中时，减少处理器对总线上DRAM或ROM的访问
* 使用单独的数据路径，替代系统总线在L2缓存和处理器之间传输数据，部分处理器将L2 Cache结合到处理器芯片上



##### 统一 vs 分立

统一

* 更高的命中率，在获取指令和数据的负载之间自动进行平衡
* 只需要设计和实现一个Cache

分立

* 消除Cache在指令的取值/译码单元和执行单元之间的竞争，在任何基于指令流水线的设计中都是重要的

***



## 10 外部存储器

### 外部存储器

> 并非冯诺依曼模型中的`Memory`，而是属于一个外部设备（I/O），但仍然属于存储器层次结构中的一员。

**为什么要使用外部存储设备？**

特性：

* 用于存储不经常使用、数据量较大的信息
* **非易失**

类型：

* 磁盘存储器（magnetic disk） -- 机械硬盘
* 光存储器（optical memory）
* 磁带（magnetic tape）
* U盘（USB flash disk），固态硬盘（solid state disk，SSD）



### 磁盘存储器

磁盘是由涂有<span style='color: orange'>**可磁化材料**</span>的<span style='color: orange'>**非磁性材料**</span>（基材）构成的圆形盘片

* 基材：铝、铝合金、玻璃...
* 玻璃基材的优势
	* 改善磁膜表面的均匀性，提高磁盘的可靠性
	* 显著减少整体表面瑕疵，以帮助减少读写错误
	* 能够支持（磁头）较低的**飞行高度**
	* 更高的硬度，使磁盘转动时更加稳定
	* 更强的抗冲击和抗损伤能力



#### 软盘

> 容量小，硬度低，已经基本被淘汰。



#### 硬盘

##### 结构

* 盘片（盘片沿轴旋转，盘片与轴是固定的）
* 读写头（所有读写头都连接在一根吊杆上，并径向移动寻找磁道）

![image-20220106151013943](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106151013943.png)

磁盘存储器每个盘片表面有一个读写磁头，所有磁头通过机械方式固定在一起，同时移动。

在任何时候，所有磁头都位于距磁盘中心等距离的**磁道**上。

对盘片进行读写操作的装置叫做<span style = 'color:red'>**磁头（head）**</span>

1. 磁头必须产生或感应足够大的电磁场，以便正确地读写
2. 磁头越窄，离盘片的距离就越近
3. 更高的数据密度需要更窄的磁头和更窄的磁道，这将导致更高的出错风险
4. **温彻斯特磁头**（Winchester head）
	1. 磁头实际上是一个空气动力箔片，当磁盘静止时，它轻轻地停留在盘片的表面
	2. 旋转圆盘时产生的空气压力足以使箔片上升到盘片表面上方



##### 读写机制

* 在读或写操作期间，磁头静止，而盘片在其下方旋转
* 磁头的数量
	* 单磁头：读写公用同一个磁头（软盘、早期硬盘）
	* 双磁头：使用一个单独的磁头进行读取（当代硬盘）

**写入机制**

* 电流脉冲被发送到写入磁头
* 变化的电流激发出磁场
* 产生的磁性图案被记录在下面的盘片表面上
* 反转电流方向，则记录介质上的磁化方向也会反转

**读取机制**

* 读取磁头是由一个部分屏蔽的**磁阻（MR）敏感器**组成，其电阻取决于在其下移动的介质的磁化方向
* 电流通过MR敏感器时，通过电压信号检测其电阻变化
* MR敏感器允许更高频率的操作，实现更高的存储密度和更快的操作速度



##### 数据组织

* 盘片上的数据组织呈现为一组同心圆环，称为**磁道（track）**

* 数据以扇区（sector）的形式传输到磁盘或传出磁盘，看起来大小不同但**存储的数据量相同**。

	> 默认值为512B

* 相邻磁道之间有**间隙（gap）**，相邻的扇区之间也留有间隙

* 磁道编号方式：最外为0，最内为N

![image-20220106151516896](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106151516896.png)

**扇区划分**

1. 恒定角速度（Constant angular velocity, CAV）

	* 增大记录在盘片区域上的信息位的间隔，使得磁盘能够以恒定的速度扫描信息
	* 优点：能以磁道号和扇区号直接寻址各个数据块
	* 缺点：磁盘存储容量受到了最内层磁道所能实现的最大记录密度的限制

	![image-20211114143858766](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211114143858766.png)

2. 多带式记录 / 多重区域记录（Multiple zone recording）

	* 将盘面划分为多个同心圆区域，每个区域中各磁道的扇区数量是相同的，距离中心较远的分区包含的扇区数多于距离中心较近的分区

		> 即相邻两个磁道的扇区数量是有可能相同，且相同扇区数量的两个磁道可以以相同的转速来访问。

	* 优点：提升存储容量

	* 缺点：需要更复杂的电路（内层圆心角大，转速需要快一点，外层相反，以维持稳定的数据传输率）

	![image-20211114144255962](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211114144255962.png)

	> 每个深色区域并不是一个磁道，而是多个磁道所组成的区域，将磁道分成多个这样的区域，保证同一个区域的磁道转速相同。



所有盘片上处于相同的相对位置的一组磁道被称为**柱面（cylinder）**

![image-20220106151755086](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106151755086.png)

##### 格式化

* 磁道必须有一些起始点和辨别每个扇区起点及终点的方法

* 格式化时，会附有一些仅被磁盘驱动器使用而不被用户存取的额外数据。

	![image-20211114145135829](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211114145135829.png)

**ID域**

1. 同步字节：特殊位模式，定义**区域的起始点**
2. 道号（磁道号，标识一个磁道）
3. 头号（磁头号，标识一个磁头）
4. 扇号（扇区号，标识一个扇区）
5. CRC（循环冗余校验码）

**数据域**

1. 同步字节
2. 数据（512B）
3. CRC

**间隙**

> 间隙的目的是为了让CRC有足够长的时间去检测与修复前面的错误，以判定后面的数据是不是所需要的数据

低级格式化和高级格式化

1. 低级格式化：清楚所有区域信息，但不能够分区域进行，只能够清楚整个硬盘的信息，且对硬盘是有损伤的。
2. 高级格式化：



##### I/O 访问时间

1. <span style = 'color: red'>**寻道时间（seek time）**</span>：磁头定位到所需移动到的磁道所花费的时间
	* 初始启动时间 + 跨越若干磁道所用的时间
2. <span style = 'color: red'>**旋转延迟（rotational delay）**</span>：等待响应扇区的起始处到达磁头所需的时间
	* 通常是磁道旋转**半周**所需的时间（rpm：转/分钟）
3. <span style = 'color: red'>**传送时间（transfer time）**</span>：数据传输所需的时间

$$
T = \frac{b}{rN}
$$

> $T$ = 传送时间
>
> $b$ = 传送的字节数
>
> $N$ = 每磁道的字节数
>
> $r$ = 旋转速率，单位是转/秒
>
> $b < N$ 时成立，相反时需要考虑寻道时间和旋转延迟

4. 平均访问时间
	$$
	T_a = T_s + \frac{1}{2r} + \frac{b}{rN}
	$$

	> $T_s$是平均寻道时间
	>
	> 当连续访问多个相邻的磁道时，跨越磁道：
	>
	> * 对于每个磁道都需要考虑旋转延迟
	> * 通常只需要考虑第一个磁道的寻道时间，但在明确知道跨越每个磁道需要的时间时需要考虑。



###### I/O访问时间示例

> 假设某个硬盘的平均寻道时间为4ms，转速为15000rpm，每磁道500扇区，每扇区512B，现读取一个由2500个扇区组成的文件

* 情况1：顺序组织，该文件占据**相邻**5个磁道的全部扇区（ $5$ 磁道 $\times 500$ 扇区/道 = $2500$ 扇区）
	* $T_a = T_s + \frac{1}{2r} + \frac{b}{rN}$
	* 平均寻道时间：4ms
	* 转速15000rpm = 250转/秒，所以r = 250转/秒
	* 平均旋转延迟 = $\frac{1}{2r} = 0.002s = 2ms$
	* 读取数据时间 $T = \frac{b}{rN} = \frac{512 \times 500}{512 \times 500 \times 250} = 0.004s = 4ms$
	* 访问后续磁道不计入寻道时间（**相邻**），因此第一个磁道的访问需要 $4 + 2 + 4 = 10ms$，后续磁道的访问需要 $4 + 2 = 6ms$
	* 总时间 $t = 10 + 4 \times 6 = 34ms= 0.034s$

* 情况2：随机存取，改文件随机分布在磁盘上的各个扇区
	* $T_a = T_s + \frac{1}{2r} + \frac{b}{rN}$
	* 平均寻道时间：4ms
	* 转速15000rpm = 250转/秒，所以r = 250转/秒
	* 平均旋转延迟 = $\frac{1}{2r} = 0.002s = 2ms$
	* 读取**一个扇区**的时间 $T = \frac{b}{rN} = \frac{512}{512 \times 500 \times 250} = 0.000008s = 0.008ms$
	* 随机存取每一次都需要**寻道**，因此每个扇区的访问时间都是 $4 + 2 + 0.008 = 6.008ms$
	* 总时间 $t = 2500 \times 6.008 = 15020ms = 15.02s$



##### 磁盘调度算法

硬磁盘存储器：I/O存储时间

硬磁盘存储器：磁头寻找道/磁盘调度
目标：当有多个访问磁盘任务时，使得平均寻道时间最小

常见的磁头寻道/磁盘调度算法：

1. 先来先服务（First Come First Service, FCFS）
2. 最短寻道时间优先（Shortest Seek Time First, SSTF）
3. 扫描/电梯（SCAN）
4. 循环扫描（C-SCAN）
5. LOOK
6. C-LOOK

###### 先来先服务

按照请求访问磁盘的先后次序进行处理
**优点：**公平简单
**缺点：**如果有大量访问磁盘的任务，且请求访问的磁道很分散，则性能上很差，寻道时间长。

**示例**:

> 假设磁头的初始位置是100号磁道，有多个任务先后陆续的请求访问55， 58， 39， 18， 90， 160， 150， 38， 184

按先后处理：

* 磁头总共移动的磁道个数：$45 + 3 + 19 + 21 + 72 + 70 + 10 + 112 + 146 = 498$
* 平均寻道长度：$\frac{498}{9} = 55.3$ 个磁道

![image-20220106153811637](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106153811637.png)

###### 最短寻道时间优先

优先处理起始位置与当前磁头位置最接近的读写任务
**优点：**每次的寻道时间最短（局部最优），平均寻道时间缩短
**缺点：**可能产生<span style='color:red'>**饥饿**</span>现象，尤其是位于两端的磁道请求。

> **饥饿现象**：即较远的磁道长时间无法被磁头寻道。因为磁头长时间在较近的几个磁道之间徘徊。

**示例**:

> 假设磁头的初始位置是100号磁道，有多个任务先后陆续的请求访问55， 58， 39， 18， 90， 160， 150， 38， 184

* 磁头总共移动的磁道个数：$(100 - 18) + (184 - 18) = 248$ 个磁道
* 平均寻道长度：$\frac{248}{9} = 27.5$ 个磁道

![image-20220106153931226](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106153931226.png)

###### 扫描/电梯（SCAN）

总是按照**一个方向**进行磁盘调度，直到该方向上的边缘，然后改变方向。
优点：性能较好，平均寻道时间短，不会产生饥饿现象。
缺点：只有到最边上的磁道才能改变磁头的移动方向，对于各个位置磁道**响应频率**不平均。

**示例**:

> 假设磁头的初始位置是100号磁道，有多个任务先后陆续的请求访问55， 58， 39， 18， 90， 160， 150， 38， 184

* 磁头总共移动的磁道个数：$(200 - 100) + (200 - 18) = 282$ 个磁道
* 平均寻道长度：$\frac{282}{9} = 31.3$ 个磁道

![](https://s2.loli.net/2022/01/06/gxuRPeLTVhUO31s.png)

###### 循环扫描（C-SCAN）

只有磁头朝某个方向移动时才会响应请求，移动到边缘后立即让磁头返回起点，**返回途中不做任何处理**。
**优点：**与SCAN算法相比，对于个位置磁道的响应频率平均。（因为到两端的磁道之后是直接回到起点，而不是再一次通过扫描回到起点）
**缺点：**与SCAN算法想法，平均寻道时间更长。（对于已经处理完的一端，可能会有新的任务，但由于磁头直接回到起点，无法扫描到新来的任务）

> **注意**：直接回到起点的时间其实是比扫描的时间要短的，因为这个过程不需要进行扫描（空载的）。起点就是 $0$ 号磁道

**示例**:

> 假设磁头的初始位置是100号磁道，有多个任务先后陆续的请求访问55， 58， 39， 18， 90， 160， 150， 38， 184

* 磁头总共移动的磁道个数：$(200 - 100) + (200 - 0) + (90 - 0) = 390$ 个磁道

	> 200 - 0 是回到起点所需要移动的磁道数，但其实这部分的时间比扫描的时间要短

* 平均寻道长度：$\frac{390}{9} = 43.3$ 个磁道

![](https://s2.loli.net/2022/01/06/4rdK5Nq8Gg2fXQH.png)

###### LOOK

SCAN算法的升级，只要磁头移动方向上不再有请求就立即改变磁头的方向（即不会到最远端的磁道）
**代价**：无法处理新任务，即到了最远端的某个任务之后，如果返回之后更远端又来了个新任务，LOOK算法无法及时处理到。
**示例**：从100 - 184，LOOK算法回头之后，又来了一个磁道190的任务，此时就无法及时处理到。

**示例**:

> 假设磁头的初始位置是100号磁道，有多个任务先后陆续的请求访问55， 58， 39， 18， 90， 160， 150， 38， 184

* 磁头总共移动的磁道个数：$(184 - 100) + (184 - 18) = 250$ 个磁道
* 平均寻道长度：$\frac{250}{9} = 27.8$ 个磁道

###### C-LOOK

C-SCAN算法的改进，只要在磁头移动方向上不再有请求，就立即让磁头返回起点。（这里的起点是**有任务的**最低磁道）

**示例**:

> 假设磁头的初始位置是100号磁道，有多个任务先后陆续的请求访问55， 58， 39， 18， 90， 160， 150， 38， 184

* 磁头总共移动的磁道个数：$(184 - 100) + (184 - 18) + (90 - 18) = 322$ 个磁道

	> 184 - 18 是回到起点所需要移动的磁道数，但其实这部分的时间比扫描的时间要短

* 平均寻道长度：$\frac{322}{9} = 35.8$ 个磁道

![](https://s2.loli.net/2022/01/06/P6JitWuywLZzXKD.png)

### 光存储器

光盘（CD）/光盘只读存储器/高清晰视频光盘（蓝光Blu-Ray DVD）...

![image-20220106154951204](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106154951204.png)

#### CD and CD-ROM

CD和CD—ROM采用类似的技术，但后者更加耐用且有纠错功能

**制造方法**

* 用精密聚焦的高强度激光束制造母盘
* 以母盘为模板压印出**聚碳酸酯**（透明的）的复制品（类似信封上滴蜡然后压印章，印章 约等于 母盘
* 在凹坑表面上镀上一层高反射材料
* 使用丙烯酸树脂保护高反射材料（金属容易被磨损
* 在聚丙烯酸树脂层上用丝网印刷术印制标签

**读取过程**
通过安装在光盘播放器或驱动装置内的低强度激光束从CD或CD-ROM处读取信息

* 如果激光束照在<span style = 'color:red'>凹坑（pit）</span>上，由于凹坑表面有些不平，因此光被散射，反射回**低强度**的激光
* 如果激光束照在<span style = 'color:red'>台（land）</span>上，台的表面光滑平坦，反射回来的是**高强度**的激光

盘片上包含<span style = 'color:red'>一条单螺旋的轨道</span>，轨道上的所有扇区长度相同

* 盘片以变速旋转
* 凹坑被激光以恒定线速度读出(内侧的角速度较大)

**优点**

1. 存储有信息的光盘可以廉价地进行大规模的复制
2. 光盘是可更换的

**缺点**

1. 它是只读的，不能更改
2. 其存取时间比磁盘存储器长的多



#### CD—R and CD-RW

CD-R

* 包含一个染色层，用于改变反射率，并且由高强度激光激活
* 生成的盘即能在CD-R驱动器上也能在CD-ROM驱动器上读出

CD-RW

* 使用了一种在两种不同相位状态下有两种显著不同反射率的材料，激光束能改变这种材料的相位
* 材料老化最终会永久失去相位可变的特性，当前的材料可用于50万次到100万次的擦除



#### 数字多功能光盘（DVD）

* DVD上的位组装更紧密：光道间隙，凹坑间距（容量达到4.7GB）

	> DVD的光驱要求激光束需要更加密集，所以DVD的光驱可以读取CD，但是反过来是不行的

* DVD采用双层结构：设有半反射层，可以通过调整焦距读取每一层（容量达到8.5GB）

* DVD-ROM可以用两面记录数据（容量达到17GB）

分类：DVD-R和DVD-ROM



#### 高清晰光盘（蓝光

通过使用更短波长的激光（在蓝-紫光范围），可以实现更高的位密度（数据凹坑相对更小）。



### 磁带

使用与磁盘类似的记录和读取技术
记录：介质时柔韧的聚酯薄膜带，外涂磁性材料
读取：

* 磁带：顺序读取（sequential-access）
	* 磁盘：直接读取（direct-access）
* 并行记录 vs 串行记录（蛇形记录，S型）



### U盘和固态硬盘

**U盘**

* 采用了快闪存储器，属于非易失性半导体存储器
* 相比于软盘和光盘：体积小，容量大，携带方便，寿命长达数年

**固态硬盘**

* 与U盘没有本质区别：容量更大，存储性能更好

* 与硬磁盘存储器相比：抗振性好，无噪声，能耗低，发热量低

	> 无磁头结构，没有轴转动和磁头转动

***



## 11 冗余磁盘阵列（RAID）

* 冗余磁盘阵列/独立磁盘冗余阵列：Redundant Arrays of Independent Disks(RAID)
* 基本思想
	* 将多个独立操作的磁盘按某种方式组织成磁盘阵列，以增加容量
	* 将数据存储在多个盘体上，通过这些盘并行工作来提高数据传输率
	* 采用**数据冗余**来进行错误恢复以提高系统可靠性
* 特性
	* 由一组物理磁盘驱动器组成，被视为单个的**逻辑**驱动器
	* 数据是分布在多个物理磁盘上
	* 冗余磁盘容量用于**存储校验信息**，保证磁盘万一损坏时能恢复数据



### RAID分类

![](https://s2.loli.net/2022/01/06/6m4ETtkHdqBQvJr.png)



### RAID 0

* 数据以条带的形式在可用的磁盘上分布
* 不采用冗余来改善性能（并非真正的RAID
* 用途
	* 高数据传输率
	* 高速响应I/O请求

**与单个大容量磁盘相比**：

* 高数据传输率：读取的时候可以多个物理磁盘并行读取，写的时候也可以对多个物理的磁盘进行同时读写。但对于单个磁盘，我们必须要进行顺序的存取。
* 高速响应I/O请求：两个I/O请求所需要的数据块可能在不同的硬盘上。因此相比单个磁盘会有更高速的响应。
* **代价**：磁盘损坏概率升高

![](https://s2.loli.net/2022/01/06/1OZv6ubwUgcX3zy.png)



### RAID 1

* 采用了数据条带
* 采用简单地备份所有数据的方法来实现冗余（即将磁盘分成了两半，一半为冗余盘，对原本数据进行拷贝）
* 好处：
	* 硬盘损坏（只有一个）对整体没有影响，（若损坏多个硬盘呢？
	* 如果有两个位于同一个磁盘的I/O请求，RAID1也可以同时响应。
	* 数据传输率也会提高，因为可以对同一个磁盘上不同条带的数据进行同时存取（冗余盘和正常使用盘同时读取）
* 坏处：对磁盘进行写操作的时候，需要写两个磁盘（冗余盘和正常使用盘），效率较低。但其实可以并行完成，取决于拷贝盘和数据盘中较慢的一个写来决定（即包含较大的寻道时间和旋转延迟的那一个写）。

**优点**：

* 高速响应I/O请求：即便是同一个磁盘上的数据块，也可以由两组硬盘分别响应
* 读请求可以由包含请求数据的两个对应磁盘中的某一个提供服务，可以选择寻道时间较小的那个
* 写请求需要更新两个对应的条带：可以并行完成，但受限于写入较慢的磁盘
* 单个磁盘损坏时不会影响数据访问，恢复受损磁盘简单

**缺点**

* 价格昂贵

**用途**

* 只限于用在存储系统软件/数据和其他关键文件的驱动器中

**与RAID0相比**

* 如果有大批的**读请求**，则RAID1能实现高速的I/O速率，性能可以达到RAID0的两倍
* 如果I/O请求有相当大的部分是**写请求**，则它不比RAID0的性能好多少。

![](https://s2.loli.net/2022/01/06/keqvRHdjhmUg7FI.png)



### RAID 01 vs RAID 10

* RAID 01 = RAID 0 + 1:先做RAID 0，再做RAID 1
* RAID 10 = RAID 1 + 0:先做RAID 1，再做RAID 0
* 两者在数据传输率和磁盘利用率上没有明显区别，主要区别是对磁盘损坏的容错能力。（RAID 01较弱，因为不能跨越RAID 0进行合作。）
* RAID 01 是先分好组的（即先组成RAID0，再组成RAID1），如果组里面有一个不能用了，那么该组的所有磁盘都会失效。这样就会导致容错率大大下降。



### RAID 2

* 采用并行存取技术
* 目标
	* <span style='color: red'>**所有**</span>磁盘都参与<span style='color: red'>**每个**</span>I/O请求的执行
* 特点
	* 各个驱动器的轴是同步旋转的，因此每个磁盘上的每个磁头在任何时刻都位于同一位置
	* 采用数据条带：条带非常小，经常只有一个字节或一个字
* 纠错
	* 对位于同一条带的各个数据盘上的数据位计算校验码（通常采用海明码），校验码存储在该条带中多个校验盘的对应位置
* 访问
	* 读取：获取请求的数据和对应的校验码
	* 写入：所有数据盘和校验盘都被访问
* 缺点
	* 冗余盘依然比较多，价格较贵
	* 适用于多磁盘易出错环境，对于单个磁盘和磁盘驱动器已经具备高可靠性的情况没有意义。

![](https://s2.loli.net/2022/01/06/3jUgZJSAI5w2Pbq.png)



### RAID 3

* 采用并行存取技术

	* 各个驱动器的轴同步旋转
	* 采用非常小的数据条带

* 对所有数据盘上同一位置的数据计算<span style='color: red'>**奇偶校验码**</span>

	* 当某一次盘损坏（已经**明确**知道哪一位是有问题的）时，可以用于重构数据
		$$
		b_0 = P(b) \oplus b_1 \oplus b_2 \oplus b_3
		$$

* 优缺点

	* 优点：能够获得非常高的数据传输率
		* 对于大量传送，性能改善特别明显
	* 缺点：一次只能执行一个I/O请求
		* 在面向多个IO请求时，性能将受损

![](https://s2.loli.net/2022/01/06/qwYTCmzalBSiu2F.png)



### RAID 4

* 采用独立存取技术

	* 每个磁盘成员的操作是独立的，各个I/O请求能够并行处理

* 采用相对较大的数据条带

* 根据各个数据盘上的数据来逐位计算奇偶校验条带，奇偶校验位存储在奇偶校验盘的对应条带上。

* 性能

	* 当执行较小规模的I/O请求时，RAID4会遭遇写损失

		* 对于每一次写操作，阵列管理软件不仅要修改用户数据，而且要修改相应的校验位。
			$$
			P'(B) = P(B) \oplus B_0 \oplus B_0'
			$$

	* 当涉及所有磁盘的数据条带的较大I/O写操作时，只要用新的数据位来进行简单的计算即可得到奇偶校验位

	* 每一次写操作必须涉及到唯一的校验盘，校验盘会成为瓶颈。

![](https://s2.loli.net/2022/01/06/felr3UOCBGMqwcE.png)



### RAID 5

* 与RAID4组织方式相似

* 在所有磁盘上都分布了奇偶校验条带

	* 避免潜在的I/O瓶颈问题

* 访问时的“两读两写”
	$$
	P'(B) = P(B) \oplus B_0 \oplus B_0'
	$$

* 

![](https://s2.loli.net/2022/01/06/hG5e7oPc3mYSft6.png)

### RAID 50

RAID 5 与RAID 0 的组合，先作RAID 5，再作RAID 0，也就是对多组RAID 5 彼此构成条带访问

RAID 50在底层的任一祖或多组 RAID 5中出现一颗硬盘损坏时，仍能维持运作；如果任一祖RAID 5中出现2颗或2颗以上硬盘损毁，整组RAID 50就会失效

RAID 50由于在上层把多组RAID 5进行条带化，性能比起单纯的RIAD 5高，但容量利用率比RAID 5要低



### RAID 6

* 采用两种不同的校验码，并将校验码以分开的块存于不同的磁盘中
* 优点
	* 提升数据可用性：只有在平均修复时间间隔内3个磁盘都出了故障，才会造成数据丢失
* 缺点
	* 写损失：每次写都要影响两个校验块

![](https://s2.loli.net/2022/01/06/xtoiYDcrHOzT6f7.png)

***



## 12  虚拟存储器

### 操作系统

操作系统：一种控制应用程序运行和在计算机用户与计算机硬件之间提供接口的程序

目标：

* 使计算机使用起来更方便
* 允许计算机系统的资源以有效的方式使用



### 存储器管理

早期计算机的主存中仅包含**系统软件**和一个用户程序。 -- 单道程序设计

现在计算机的主存中包含**操作系统**和若干个用户程序

* 当所有任务都需要等待I/O时，为了避免处理器处于空闲状态，需要尽可能让更多的任务进入主存
* 多道程序设计：让处理器一次处理多个任务，提高处理器的利用率

存储器管理

* 在多道程序系统中，主存需要进一步划分给多个任务，划分的任务由操作系统动态执行
* 这里不考虑“**进程**”这一概念。



### 如何将更多任务装入主存

1. 增大主存容量
2. 使用交换（exchange）技术
	* 当主存中没有处于就绪的任务时，操作系统调入其他任务来执行
	* 分区（partitioning）与分页（paging）
3. 虚拟存储器
	* 请求分页：每次访问仅将当前需要的页面调入主存，而其他不活跃的页面放在外存磁盘上
	* 虚拟地址

#### 分区方式

* 分区方式：将主存分为两大地址
	* 系统区：固定的地址范围内，存放操作系统
	* 用户区：存放所有用户程序



##### 简单固定分区

* 用户区划分成**长度不等**的**固定长**分区
* 当一个任务调入主存时，分配一个可用的，能容纳它的、最小的分区（一个区**只能**放一个任务，不能够将两个小任务放在同一个分区中）
* 优点：简单
* 缺点：浪费主存空间



##### 可变长分区

* 用户区按每个任务所需要的内存大小进行分配

* 优点：提高了主存的利用率

* 缺点：时间越长，存储器中的**碎片**就会越多

	> 做完大任务后的内存区域存入了一个小任务，就会留下一个较小的碎片的内存空间。（分散的，没有办法被联合起来使用的）

![](https://s2.loli.net/2022/01/06/zjkACeMPnmiTWdX.png)



#### 分页方式

基本思想：

* 把主存分成**固定长**并且比较小的存储块，称为<span style = 'color: red'>**页框（page frame）**</span>，每个任务也被划分成固定长的程序块，称为<span style = 'color: red'>**页（page）**</span>

* 将页装入页框中，且**无需采用连续的页框**来存放一个任务中所有的页

> 逻辑地址：指令中的地址
>
> 物理地址：实际主存地址
>
> 页表：能够通过页表知道任务在主存中的**物理地址**
>
> 流程：指令中的逻辑地址通过页表查询到对应的物理地址，然后到主存中找到对应地址中的数据



### 虚拟存储器

问题：内存的大小是有限的，但对内存的需求不断增加

#### 基本思想

* <span style = 'color: red'>**请求分页**</span>：仅将当前需要的页面调入主存
	* 通过硬件将**逻辑地址**转换为**物理地址**
	* 未命中时在主存和硬盘之间交换信息

**优点**：

* 在不扩大物理内存的前提下，可以载入更多的任务
* 编写程序时不需要考虑可用物理内存的状态
	* 程序员认为可以独享一个连续的、很大的内存
* 可以在大于物理内存的逻辑地址空间中编程

**设计的一些问题**：

1. 页大小
2. 映射算法：全相连映射
3. 写策略：写回
4. 类型
	1. 分页式虚拟存储器
	2. 分段式虚拟存储器
	3. 段页式虚拟存储器

> Cache和主存的速度差距比主存和硬盘的速度差距小很多，所以我们应该尽可能减少对硬盘的访问，提高对主存的利用率。
>
> Cache比主存快10倍，主存比硬盘快100000多倍



#### 分页式虚拟存储器

主存储器和虚拟地址空间都被划分为大小相等的页面

* 虚拟页（virtual page, VP）/逻辑页（logical page）：虚拟地址空间中的页面
* 物理页（physical page, PP）/页框（page frame）：主存空间中的页面

##### 页表

* 页表中包含了所有<span style = 'color: red'>**所有虚拟页**</span>的信息，包括虚拟页的存放位置、装入位（valid）、修改位（dirty）、存取权限位等
* 保存在主存中
* 编写程序时认为有一块很大、连续的存储空间，写的是虚拟地址
* 虚拟地址：虚拟页号 + 页内偏移量



**页表的存放位置**

1. null：还未存放任何东西，没有指针指向实际的主存物理地址
2. PPx（x为数字）：指向主存中的一块
3. 空：指向磁盘的一块

> 存放地址中存储的是一样长的数据，以指向内存中的页的物理地址的长度为准，不需要存放虚拟页号（因为页表中存储的是所有的虚拟页，不会再有多的虚拟页了）

<span style='color :red'>虚拟页号</span> + <span style = 'color: blue'>页内偏移量</span> -> <span style='color: green'>物理页号</span> + <span style = 'color: blue'>页内偏移量</span>

> 页内偏移量相同，因为虚拟页和物理页的大小是一样的

![](https://s2.loli.net/2022/01/06/pg2CJkdQSysHK8u.png)



##### 快表

> Translation Lookaside Buffer, TLB

页表的使用增加了主存的访问次数

为了减少访问主存的次数，把页表中**最活跃**的几个页表项复制到Cache中

后备转换缓冲器（简称“快表”）：将页表项放入Cache中

* 映射：关联映射，组关联映射
* 替换：随机替换

主存中的页表相应地称之为“慢表”



##### CPU访存过程

![](https://s2.loli.net/2022/01/06/UMwnlvkasejS4Fi.png)

![](https://s2.loli.net/2022/01/06/3LYAtojXCS1mrDV.png)

> 注意如果页表项不在TLB中，我们需要在读取数据的同时更新TLB



##### TLB、页表、Cache的缺失组合

![](https://s2.loli.net/2022/01/06/SiZ73NgQtuMzd58.png)



#### 分段式虚拟存储器

将程序和数据分成不同长度的段，将所需的段加载到主存中。

虚拟地址：段号 + 段内偏移量

与分页式虚拟存储器相比：

* 分页式虚拟存储器：
	* 优点：实现简单、开销少
	* 缺点：一个数据或一条指令可能会横跨两个页面
* 分段式虚拟存储器
	* 段的分界与程序的自然分界相对应，易于编译
	* 会产生碎片，长度不固定



#### 段页式虚拟存储器

将程序和数据分段，段内再进行分页

* 每个分段都有一个页表

虚拟地址：段号 + 页号 + 页内偏移量

优点：程序按段实现共享与保护

缺点：需要多次查表

***



## 13 总线

> 总线时连接两个或多个设备的通信通路

### 类型

* **芯片内部总线**：连接芯片内部的各个部分
	* 例：CPU中连接寄存器、ALU等部分
* <span style = 'color : red'>**系统总线**</span>：连接CPU、存储器、IO控制器和其他功能设备
* **通信总线**：连接主机和I/O设备，或连接**不同**的计算机系统

> Intel架构中的“系统总线”
>
> intel架构中的系统总线指的是：IO连接桥和CPU之间连接的总线，与上面所说的系统总线有略微不同（特指的系统总线

![image-20220106170026106](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106170026106.png)



### 数据线、地址线和控制线

1. 数据线：在系统组件之间传输数据

	* 数据线的数量决定了一次**可以传输的数据**大小（数据的位数，一根一位）

2. 地址线：在数据线和I/O端口上指定数据的来源和去向

	* 地址线的数量决定了**寻址空间**的大小（地址的位数，一根一位）

	> 特例：可以将64位地址分成两次32位地址传输（先行地址后列地址

3. 控制线：控制对数据线和地址线的存取和使用

	* 时钟（clock）：用于总线同步操作
	* 总线请求（bus request）：表示模块需要获得对总线的控制
	* 总线允许（bus grant）：发出请求的设备已经被允许控制总线
	* 中断请求（interrupt request）：表示某个中断正在悬而未决
	* 中断响应（interrupt ACK）：未决的中断请求被响应
	* 存储器读（Memory Read）：使所寻址单元的数据放到总线上
	* 存储器写（Memory Write）：引起总线上的数据写入被寻址的单元
	* I/O读（I/O Read）：使被寻址的I/O端口的数据放到总线上
	* I/O写（I/O Write）：引起总线上的数据输出到被寻址的I/O端口



### 总线上数据传输的特点

总线可以被多个设备监听，但同一时刻只能由<span style='color: red'>**一个设备**</span>发送数据

* 如果同一时刻多个设备同时发送数据，会造成数据之间的混淆
* 使用总线进行数据传输
	* 如果连在总线上的某个设备希望向另一个设备**发送数据**，需要：
		1. **获得总线的使用权**
		2. 通过总线传输数据
	* 如果连在总线上的某个设备希望向另一个组件**请求数据**，需要：
		1. **获得总线的使用权**
		2. 通过总线向另一个设备发送请求，等待另一个设备发送数据
* 某个设备**已经**在使用总线时，其他设备不能获得总线的使用权（无论优先级



### 设计要素

* 用途：专用总线，复用总线

* 仲裁（arbitration）：集中式，分布式

* 时序：同步时序/异步时序/半同步时序/分离事务

* 总线带宽（bandwidth）和数据传输率（data transfer rate）

* 总线层次结构：单总线，双总线，多总线



#### 用途

1. 专用（dedicated）总线：始终只负责一项功能，或始终分配给特定的计算机组件。
	* 优点：高吞吐量，减少总线冲突
	* 缺点：增加了系统的规模和成本
2. 复用（multiplexed）总线：将同一线路用于多种用途
	* 优点：使用的布线数量少，节省空间和成本
	* 缺点：每个模块需要更复杂的控制电路，且共享可能会降低性能



#### 仲裁

总线仲裁：当多个设备需要与总线通信时，通过某种策略选择一个设备

平衡因素：

1. 优先级：优先级高的设备优先被服务
2. 公平性：优先级最低的设备不能一直被延迟

##### 仲裁方案

1. 集中式（centralized）：由**仲裁器（arbiter）**或**总线控制器（bus controller）**负责分配总线使用权

	  * 链式查询/菊花链（daisy chain）

		> 所有的设备都是串行连接的，并将允许信号从优先级最高的设备下发到优先级最低的设备（从高到低
		>
		> 总线仲裁器收到请求后，在**总线不忙**的情况下，发起允许信号
		>
		> 如果某个设备收到了允许信号并且发起了总线请求，该设备将总线设置为**繁忙状态**，允许信号将不再被进一步传递。（繁忙线是双向的，可以由设备发起也可以发送到设备，此时其他优先级更低的设备会知道总线繁忙
		>
		> 优点：确定优先级很简单（优先级高在前面，优先级低在后面），可以很灵活地添加设备
		>
		> 缺点：不能保证公平性，对电路故障敏感（串连），限制总线的速度
		>
		> ![image-20211206191415224](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211206191415224.png)

		流程：

		1. 首先设备检查繁忙线是否被设成忙，如果没有被设成忙则发起请求信号，
		
		2. 总线仲裁器收到请求信号后，检测繁忙线是否被设为忙，如果不忙的话则发起允许信号。

	  3. 允许信号从优先级高的设备一直往优先级低的设备传递（通过允许线串连起来），遇到发出请求信号的设备就停止，该设备将繁忙线设成忙，同时开始使用总线

			计数器查询（query by a counter）
		
		> 将总线允许线替换为**设备ID线**（$\log_2n$根 -- $n$个设备，并非图上所绘制出来的一根）
		>
		> 如果总线空闲，总线仲裁器通过设备ID线发送计数
		>
		> 如果当前发送请求的设备ID等于裁决器当前的计数，裁决器将停止计数，设备将总线设置为忙
		>
		> 与链式的区别：报数顺序并不固定，可以更改，即同一个设备的**设备ID**在每次请求时可能不同，这样就可以灵活的确定设备的优先级
		>
		> 优点：通过使用不同的初始计数，可以灵活地确定设备优先级
		>
		> * 强调优先级：从1开始
		> * 强调公平性：从下一个设备的ID开始
		>
		> 对电路故障不敏感。
		>
		> 缺点：需要添加设备ID线，需要解码和比较设备ID信号，限制总线的速度
		>
	  > ![image-20211206191440810](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211206191440810.png)

		* 独立请求（independently request）
		
		> 每个设备都有自己的总线请求线和总线允许线
		>
		> 当一个设备请求总线时，它通过总线请求线将请求信号发送给总线仲裁器
		>
		> 总线仲裁器决定哪个设备可以使用总线
		>
		> * 决定策略：固定优先级，公平链式，LRU，FIFO，...
		>
		> 优点：快速响应，可编程的优先级
		>
		> 缺点：复杂的控制逻辑，更多的控制电路
		>
		> ![image-20211206191459891](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211206191459891.png)


2. 分布式（distributed）：每个设备都包含访问控制逻辑，**各设备共同作用**分享总线

	* 自举式

		> **固定优先级**
		>
		> 每个设备在其总线请求线上发送请求，最低优先级的设备没有请求线
		>
		> 每个设备自行判断自己是否在请求总线的设备中优先级最高
		>
		> 过程：优先级高的设备会发送信号，比该设备优先级低的设备会监听该信号，如果优先级高的设备要使用总线，就会发送信号，优先级低的设备就不能使用总线（监听到了优先级高的设备要使用总线的信号
		>
		> ![image-20211206191223594](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211206191223594.png)

	* 冲突检测

		> 当一个设备想要使用总线时，它会检查宗贤是否繁忙。如果总线空闲，设备使用总线
		>
		> 冲突：如果两个设备发现总线空闲，它们可能同时使用总线
		>
		> * 在传输数据时，设备会监听总线，检查是否存在冲突
		> * 如果发生冲突，所有使用总线的设备将停止数据传输，并分别在随机间隔时间后再次请求总线。



#### 时序

确定每个总线事务的开始和结束时间

> 总线事务：地址 + 数据 + ... + 数据

类型：

1. 同步时序：事件的发生由时钟决定
2. 异步时序：一个事件的发生取决于前一个事件的发生
3. 半同步：同步时序和异步时序相结合
4. 分离事务：设备准备数据期间释放总线



##### 同步时序

优点：更容易实现和测试

缺点：所有设备共享同一个时钟，总线长度收到时钟偏差的限制

![](https://s2.loli.net/2022/01/06/CE52qJBViDUY43s.png)



##### 异步时序

1. 握手策略：ready线和ACK线进行三次握手变成全互锁

  > 非互锁：No interlock
  >
  > 半互锁：Semi-interlock
  >
  > 全互锁：interlock
  >
  > 以全互锁的三次握手为例来讲解一下，非互锁就是取了全互锁的第一次握手，半互锁是取了全互锁的第一次和第二次握手。
  >
  > Ready信号：提供东西给总线时需要告诉总线该东西准备就绪（上升沿表示），下降沿表示撤掉准备就绪的信号，目的是为了下一次的准备就绪
  >
  > ACK信号：总线告诉设备自己已经获得了数据（上升沿表示已经取到了数据）
  >
  > 第一次握手：Ready信号在上升沿处，代表设备已经准备好了数据，总线可以获得数据，于是Ready线和ACK线握手，告诉ACK线该设备已经准备好数据，Ack线可以获得该数据了
  >
  > 第二次握手：Ack线取得数据之后，代表总线已经获得了该数据，此时Ready线上的Ready信号可以撤去，因此发生第二次握手，Ack线告诉Ready线自己已经取好了数据，不需要知道设备准备就绪了
  >
  > 第三次握手：Ready线撤下信号之后，代表进入到下一个取数据的周期中，因此发生第三次握手，告诉Ack信号应该撤下代表“已经取好数据”的信号，因为此时进入下一个周期，信号应该是还没有取好的。

2. 优点：可以灵活地协调速度不同的设备

3. 缺点：对噪声敏感

![](https://s2.loli.net/2022/01/06/m7TsZF8uYHMGpnf.png)

![](https://s2.loli.net/2022/01/06/XoOrfPB45RF32js.png)



##### 半同步时序

为了减少噪声的影响，在异步计时中使用时钟。

准备和响应信号在时钟上升沿有效

结合同步和异步定时的优点。



##### 分离事务

将一个总线事件分离为两个过程

优点：增加总线利用率

缺点：增加每个总线事件的持续时间和系统复杂度



#### 总线带宽和数据传输数率

1. **总线带宽**（bus bandwidth）：总线**最大**数据传输速率

	> 不要考虑总线仲裁，地址传输等因素

2. 数据传输速率

	> 考虑地址传输，握手等因素

3. 总线宽度：组成总线的线数（**与总线带宽不同**）

	> 数据总线越宽，一次传输的数据位数就越多
	>
	> 地址总线越多，一次传输的地址位数就越多



**例1**

> 假设同步总线的时钟周期为50ns，每次传输需要一个时钟周期，异步总线每次握手需要40ns。两个总线都是32位宽，内存的数据准备时间为200ns。当从存储器读出一个32位的字时，计算两个总线的数据传输率

* 同步总线
	* 发送指令和地址到内存：50ns
	* 内存准备数据：200ns
	* 将数据传输到CPU：50ns
	* 数据传输率 = $\frac{32\ bit}{(50 + 200 + 50) \ ns} = 106.7\ Mbps$
* 异步总线
	* 步骤1：40ns
	* 步骤2、3、4、数据准备：$\max(40ns \times 3, 200ns) = 200ns$
	* 步骤5、6、7：$40ns \times 3 = 120ns$
	* 数据传输率 $ = \frac{32\ bit}{(40 + 200 + 120)\ ns} = 88.9\ Mbps$



**例2**

> 假设系统具有以下特征：
>
> 1. 它支持访问大小为4到16个字（每个字32bit）的块
> 2. 同步总线具有64位宽和200MHz时钟频率，需要1个时钟周期来传输地址或64位数据
> 3. 在两个总线事务之间有2个空闲时钟周期
> 4. 内存访问准备前4个字需要200ns，后面每4个字准备需要20ns
> 5. 当前面的数据在总线上传输时，内存可以同时读取后面的数据
>
> 如果读取256个字，分别计算每次传输4个字和16个字时的数据传输速率，传输时间和每秒总线事务数

* 每次传输4个字
	* 总线事务：地址 + 4个字
		* 地址传输：1个时间周期
		* 数据准备：200ns（40个时间周期）
		* 数据传输：2个时间周期
		* 空闲：2个时钟周期
	* 总共：$\frac{256}{4} \times (1 + 40 + 2 + 2) = 2880$ 个时间周期
	* 传输时间（时钟周期 $5ns$）：$2880 \times 5ns = 14400ns$
	* 每秒总线事务：$\frac{1s}{14400 ns} \times 64 = 4.44M$
	* 数据传输速率 $= \frac{256 \times 32bit}{14400ns} = 568.9Mbps$
* 每次传输16个字
	* 总线事务：地址 + 16个字
		* 地址传输：1个时间周期
		* 数据准备（前四个字）：$200ns$（40个时间周期）
		* 数据传输：同步总线一次传输两个字，在传输两个字的同时准备数据的下4个字，传输需要2个时钟周期，读取下4个字需要 $20ns$，即4个时钟周期
		* 空闲：2个时钟周期
	* 总共：$\frac{256}{16} \times (1 + 40 + 3 \times \max(2, 4) + 2 + 2) = 912$ 个时钟周期（其中倒数第二个2是最后一次数据传输，此时没有数据需要准备了，所以直接传输）
	* 传输时间：$912 \times 5ns = 4560ns$
	* 每秒总线事务数 = $\frac{1s}{4560ns} \times 16 = 3.51M$
	* 数据传输速率 = $\frac{256 \times 32bit}{4560} = 1796.5 Mbps$



##### 提高总线的数据传输率

1. 提高时钟频率
2. 增加数据总线宽度
	* 每次传输更多的数据（成本：更多的总线线路
3. 块传输
	* 传输一次地址就传输一块数据（成本，高复杂性
4. 分离总线事务
	* 减少总线空闲时间（成本：复杂性高，增加每个事务的持续时间
5. 分离地址线和数据线
	* 同时传输地址和数据（成本：更多的总线线路



#### 总线层次结构

##### 单总线结构

* CPU、存储器和I/O模块都连接到一条<span style='color: red'>**系统总线**</span>
* 优点：简单、易于扩展
* 缺点：
	* 连接的设备越多，总线长度越大，传输延迟也就越大
	* 聚集的传输请求接近总线容量后，总线成为瓶颈

##### 双总线结构I

* 在CPU和存储中间增加一个<span style='color: red'>**存储器总线**</span>
* 优点：增加CPU和存储器之间的传输效率，同时降低系统总线的负担

##### 双总线结构II

* 将系统总线分为存储器总线、**I/O总线** 和 **IOP**（input/output processor）
* 优点：降低I/O对总线的负担

##### 多总线结构I

* 在 双总线结构II 的基础上增加一个<span style='color: red'>**本地总线（local bus）**</span>来连接CPU和cache
* 优点：分离了 CPU 和 I/O 的交互

##### 多总线结构II

* 将系统总线分为存储器总线、I/O总线和<span style='color:red'>**DMA总线**</span>

* 优点：增加I/O效率

##### 多总线结构III

* 增加一个高速I/O

***



## 14 指令系统

* <span style='color: orange'>**指令集**</span>：CPU能执行的各种不同指令的集合
* 程序由存储在内存中的一组指令组成
* 计算机的基本功能是执行程序
* CPU通过执行指定的指令来完成实际工作



指令时计算机处理的**最基本单位**

* 操作码（指令执行的内容）+操作数（要操作的对象）

多周期实现方案

* 可以将一条指令的执行分解为一系列步骤
	* 取指令，译码/取寄存器，执行/有效地址/完成分支，访问内存，存储结果



### 指令的要素

* 操作码：指定将要完成的操作
* 源操作数引用：操作会涉及一个或多个源操作数，这是操作所需的输入
* 结果操作数引用：操作可能会产生一个结果
* 下一指令引用：告诉处理器这条指令处理完去哪里去取下一条指令



### 指令表示

在计算机内部，指令由一个<span style='color: orange'>**位串**</span>（01串）来表示

**指令格式**：对应于指令的各要素，这个位串划分成几个字段

* 大多数指令集使用不止一种指令格式

机器指令符号表示法

* 操作码被缩写成助记符来表示

	> ADD：加，SUB：减，MUL：乘，DIV：除，LOAD：从存储器装入，STOR：保存到存储器

* 操作数也可以用符号表示

	> 用寄存器编号或内存地址替换操作数



### 操作码

不同计算机上操作码的数目变动是很大的

所有计算机上都会存在相同的常用操作类型

1. 数据传输
2. 算术运算
3. 逻辑运算
4. 转换
5. 输入/输出
6. 系统控制
7. 控制转移



#### 数据传送

* 指明源和目标操作数的位置
* 指明将要传送数据的长度
* 指明每个操作数的寻址方式



#### 算术运算

一条算术指令的执行会涉及数据传送操作，来为算术和逻辑单元准备输入，并传送逻辑单元的输出。

![image-20220106201212395](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106201212395.png)



#### 逻辑运算

* 位操作：操作一个字或其他可寻址单元中的个别位
* 移位和旋转

> 算术右移补充符号位，逻辑右移补充0
>
> 逻辑左移和算术左移都是补充0

![](https://s2.loli.net/2022/01/06/3yz8IhpWSv9GjKE.png)



#### 输入/输出

* 各种输入/输出方法仅有少数输入/输出指令实现，具体操作由参数、代码或命令字指定



#### 控制转移

* 分支指令（亦称为跳转指令）
* 跳步指令
* 过程调用指令

![](https://s2.loli.net/2022/01/06/HGBlvTyNdDFRJ5p.png)



##### 分支/跳转指令

把将要执行的下一条指令的地址作为它的**操作数**之一

![](https://s2.loli.net/2022/01/06/fF9xDJkdvHOIKNm.png)

##### 跳步指令

包含一个隐藏地址，该隐含地址等于**下一指令地址**加上该指令的长度之和

> 下一指令地址：取指周期过后PC已经加一，指向了下一条指令的地址

##### 过程调用指令

> 问题：存取函数跳转之后的返回的地址
>
> 涉及由目前位置转移到过程的调用指令和由过程返回到调用发生位置的返回指令

1. 方法一：用寄存器：只能用于没有嵌套的函数调用

	> $$
	> RN(register) \longleftarrow PC + \Delta \\
	> PC \longleftarrow X(\text{函数调用的首地址})
	> $$

2. 方法二：返回地址存于过程开始处（可以解决嵌套调用的问题，但递归时会修改掉返回地址，出现错误

	> $$
	> X \longleftarrow PC + \Delta \\
	> PC \longleftarrow X + 1
	> $$

3. 方法三：使用栈：每次调用函数就将返回地址压入栈中

![image-20220106201906613](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106201906613.png)

![](https://s2.loli.net/2022/01/06/xe8gsDhAcdLJUaE.png)



### 操作数

常见类型：地址、数值、字符、逻辑数据

#### 地址

一个指令需要有**4个地址引用**：2个源操作数，1个目的操作数，以及下一指令地址

> 下一指令地址是隐含的

地址数量

* 每条指令中的地址数目越少

	> 1. 指令的长度越短，不需要复杂的CPU
	> 2. 使程序总的指令条数更多，导致执行时间更长，程序也更长更复杂

* 对于多地址指令，普遍具有多个通用寄存器可用，允许某些运算只使用寄存器即可完成，从而使执行加快。

#### 数值

* 计算机存储的数值是受限的
	* 集齐可表示数值的幅值是有限的
	* 浮点数情况下数值精度是有限的
* 数值数据的类型
	* 二进制整数或定点数
	* 二进制浮点数
	* 十进制数

#### 字符

ASCII：每个字符被表示成唯一的7位二进制串

UNICODE：16/32位

#### 逻辑数据

将一个 $n$ 位单元看成是由 $n$ 个 $1$ 位项组成，每项有值0或1

* 存储一个布尔或者二进制数据项序列，序列中的每个值只能取1（真）或0（假）
* 有利于实现对数据项的具体位进行操纵

#### 大端序和小端序

大端：高位数据存在低地址

小端：高位数据存在高地址

> 对一个字节（同一个地址里的数据），都是高位在前低位在后，即大端序

![](https://s2.loli.net/2022/01/06/xgX4fk69EaGnDAI.png)

* 在两种策略中每个数据项有同样的地址
* 在任何一个给定的多字节值中，小端的字节排序是大端的反序，反之亦然
* 端序不影响结构中数据项的次序



#### 操作数引用

* 操作数的实际值
* 操作数的地址
	* 寄存器
	* 主存 / 虚拟内存

### 寻址方式

> 规定：
>
> $A$：指令中地址字段的内容
>
> $R$：指向寄存器的指令地址字段内容
>
> $EA$：被访问位置的实际（有效）地址
>
> $(X)$：存储器位置 $X$ 或寄存器 $X$ 的内容

#### 立即寻址

* 方式：操作数**实际出现**在指令中
* 用法：定义和使用常数或设置变量的初始值
* 算法：操作数 = $A$
* 优点：除了取指令之外，获得操作数不要求另外的存储器访问
* 缺点：数的大小受限于地址字段的长度

![image-20220106204119524](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106204119524.png)

#### 直接寻址

* 方式：地址字段含有操作数的有效地址
* 用法：早期计算机常用，在当代计算机体系结构中不多见
* 算法：$EA = A$
* 优点：只要求1次存储器访问，且无需为生成地址而专门计算
* 缺点：有限的地址空间

![image-20220106204129682](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106204129682.png)

#### 间接寻址

* 方式：地址字段指示一个存储器字地址，而此地址保存有操作数的**全长度**地址
* 算法：$EA = (A)$
* 优点：扩大了地址空间
* 缺点：取操作数需要2次访问存储器
* 解释：地址引用的数量限制可能是有益的

![image-20220106204150850](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106204150850.png)

#### 寄存器寻址

* 方式：地址字段指示的是寄存器
* 算法：$EA = R$
* 优点：指令中仅需要一个较小的地址字段，且不需要存储器访问
* 缺点：地址空间十分有限
* 解释：寄存器寻址只有在被有效使用的时候才有意义

![image-20220106204420195](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106204420195.png)

#### 寄存器间接寻址

* 方式：地址字段指示寄存器
* 算法：$EA = (R)$
* 优点：扩大了地址空间，比间接寻址少1次存储器访问
* 缺点：相对于寄存器寻址，需要多1次存储器访问

![image-20220106204516901](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106204516901.png)

#### 偏移寻址

* 方式：结合直接寻址和寄存器间接寻址能力
* 算法： $EA = (R)+A$
* 类型：
	* 相对寻址
	* 基址寄存器寻址
	* 变址
* 解释：偏移寻址要求指令有两个地址字段，至少其中一个是显式的

![image-20220106204659580](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106204659580.png)

##### 相对寻址

* 方式：隐含引用的寄存器是程序计数器（Program Counter, PC）

	* 此指令**后续的下一条指令**的地址加上地址字段的值产生有效地址

		> 取指周期之后PC就加一了，已经指向了下一条指令的地址

* 用法：大多数存储器访问都相对靠近正在执行的指令，相对寻址可节省指令中的地址位数

* 算法： $EA = (PC) + A$

* 优点：利用<span style='color: red'>**程序局部性**</span>原理，节省指令中地址的位数

##### 基址寄存器寻址

* 方式：被引用的寄存器含有一个存储器地址，地址字段含有一个相对于那个地址的偏移量（通常是无符号整数表示）
	* 寄存器引用可以是显式的，也可以是隐式的
* 算法：$EA = (R) + A$
* 用法：虚拟内存空间中的程序重定位

##### 变址寻址

* 方式：指令地址字段引用一个主存地址，被引用的寄存器含有对于该地址的一个正的偏移量
* 算法：$EA = A + (R)$
* 用法：为完成重复操作提供一种高效机制
* 扩展：结合间接寻址和变址寻址
	* 前变址：$EA = (A + (R))$
	* 后变址：$EA = (A) + (R)$

#### 栈寻址

* 方式：栈指针保存在寄存器中，对寄存器中栈位置的访问实际上是一种寄存器间接寻址方式
* 解释：与栈相关的是一个指针，它的值是栈顶地址，或者当栈顶的两个元素已在CPU寄存器内，此时栈顶指针指向栈顶的第三个元素

##### 栈

栈（stack）是有序元素组，一次仅能存取它的一个元素

* 栈顶（top）：存取元素的点
	* LIFO
* 栈底（base）：栈中最后一个元素

栈的操作：push，pop，一元操作（对栈顶元素操作完成后以结果替代栈顶元素），二元操作（取栈顶的两个元素进行操作，结果放到栈顶）



**栈的实现**

* 栈基（base）：保存为栈保留的内存块底部位置的地址
* 栈限（limit）：保存为栈保留的内存块另一端的地址
* 栈指针（pointer）：保存栈顶的地址
* 向上/向下增长：向着地址增大/减小的方向增长

**栈的应用：表达式求值**



### 指令格式

* 指令格式通过它的各个构成部分来定义指令的位安排
* 一个指令格式必须包含一个操作码，以及隐式或显式的、零个或多个操作数
* 指令格式必须显式或隐式地为每个操作数指定其寻址方式
* 大多数指令集使用不止一种指令格式



### 指令格式的设计原则

* 指令尽量短
	* 指令占用存储空间小
* 有足够的操作码位数
	* 要为操作类型不断增加预留
* 操作码的编码必须有唯一的解释
	* 操作码译码时要么是唯一的合法编码，要么是不合法的
* 指令长度是字节的整数倍
	* 与内存按照字节寻址相对应，便于指令的读取和地址计算
* 合理选择地址字段的个数
	* 涉及到指令长度和规整性，是空间和时间开销权衡的结果
* 指令尽量规整
	* 简化硬件实现

#### 指令长度

> 最明显的权衡考虑是在强有力的指令清单和节省空间之间进行
>
> * 编程人员希望更多的操作码、更多的操作数、更多的寻址方式和更大的地址范围
> * 指令长度变短可以节省存储空间和减少数据传送时间

指令长度应该是字符长度或定点数长度的**整数倍**

指令长度应该等于存储器的传送长度（即数据总线宽度），或者这两者的其中之一是另一个的整数倍

#### 位的分配

> 操作码数目和寻址能力之间存在着权衡考虑

变长的**操作码**（指令长度固定

* 使用一个最小操作码长度，但是对于某些操作码，可通过使用指令附加位的方法来指定附加的操作

使用寻址位的考虑因素

* 寻址方式的种数
* 操作数的数量
* 寄存器与存储器比较：能用于操作数引用的寄存器越多，指令需要的位数越少
* 寄存器组的数目：对于固定数目的寄存器，功能上的分开将使指令只需较少的位数
* 地址范围
* 寻址粒度：使用较大的字时，需要的地址位更少

##### 变长指令

提供不同长度的各种指令格式

优点：

1. 易于提供大的操作码清单，而操作码具有不同的长度
2. 寻址方式能更灵活，指令格式能将各种寄存器和存储器引用加上寻址方式予以组合

缺点：

1. 增加CPU复杂程度

取至少等于最长指令长度的几个字节或几个字



#### 指令集设计

##### 设计的基本问题

1. 操作指令表：应该提供多少和什么样的操作，操作有多复杂
2. 数据类型：对哪几种数据类型完成操作
3. 指令格式：指令的位长度、地址数目、各个字段的大小等
4. 寄存器：能被指令访问的寄存器数目以及它们的用途
5. 寻址：寻址方式的种类以及有效地址的计算
6. 下一条指令地址的确定：通常通过PC寄存器来实现

***



## 15 指令周期和指令流水线

### 指令周期

#### 指令周期

指令周期：处理单个指令的过程

* 取指周期：从内存中提取一条指令
* 执行周期：执行所提取的指令

只有当机器关闭，发生某种不可恢复的错误或遇到停止计算机的程序指令时，程序执行才会停止

![image-20220106211614513](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211614513.png)

![image-20220106211626707](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211626707.png)

#### 带中断的指令周期

中断禁止 和 中断允许

![image-20220106211635054](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211635054.png)

![image-20220106211652049](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211652049.png)

#### 间址周期

指令的执行可能涉及一个或多个存储器中的操作数，它们每个都要求一次存储器访问

使用间接寻址，还需要额外的存储器访问

<span style='color: orange'>间址周期</span>：把间接地址的读取堪称是一个额外的指令子周期

![image-20220106211713552](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211713552.png)

![image-20220106211722608](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211722608.png)



### CPU的任务

1. 取指令：CPU必须从存储器（寄存器、Cache、主存）读取指令
2. 解释指令：必须对指令进行译码，已确定所要求的动作
3. 取数据：指令的执行可能要求从存储器或输入/输出（I/O）模块中读取数据
4. 处理数据：指令的执行可能要求对数据完成某些算数或逻辑运算
5. 写数据：执行的结果可能要求写数据到存储器或I/O模块



#### CPU需求：寄存器

* CPU需要在指令周期中临时保存指令和数据
* CPU需要记录当前所执行指令的位置，以便知道从何处得到下一条指令

MBR：存储缓冲寄存器 / 存储数据寄存器（MDR）

MAR：存储地址寄存器

IR：指令寄存器

PC：程序计数器

> 取完指令之后PC就会加一，而不是等到指令执行完毕



## 数据流

### 取指周期

![image-20220106211932608](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211932608.png)

过程描述

1. PC通过MAR（因为MAR才和系统总线中的地址总线直连）将当前指令的地址放到**地址总线**上，控制器发送信号到**控制总线**告知存储器读取地址上的指令地址（中间省略总线的三次握手等机制），存储器获得了当前指令的地址
2. 然后存储器将指令放到数据总线上，MBR读取数据总线上的数据并放到IR（指令寄存器）中
3. 取指周期结束，**控制器控制PC+1**

### 间址周期

![image-20220106211943105](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211943105.png)

过程描述：

1. 操作数在MBR中，MBR将该数据传送给MAR，MAR将数据放在地址总线上（此时传输的是间接地址，目标是获得**有效地址**）。然后控制器发送信号到控制总线上，存储器读取该信号并从地址总线上读取内容。
2. 存储器读取该地址中的内容（有效地址）放到数据总线上，MBR读取数据总线上的信息

### 中断周期

![image-20220106211956305](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106211956305.png)

过程描述

1. 控制器发送信号给PC，PC将其存放的内容（即**下一条指令的地址**）放到MBR中，MBR将该内容放到数据总线上。

2. 控制器向MAR发送信号，MAR将**PC内容在存储器中保存的地址**放到地址总线上

3. 控制器发送信号到控制总线，存储器读取该信号，读取地址总线上的地址和数据总线上的内容，在该地址中存放PC的内容（即数据总线上的内容）

	> 这里一般会压在栈顶，通过CPU内部的栈指针寄存器我们可以知道栈顶的地址，然后控制器会控制MAR将该地址传送到地址总线上，从而使得中断周期执行完的时候程序可以返回到原来的地方

### 指令流水线

流水处理（pipelining）

> 如果一个产品要经过几个制作步骤，通过把制作过程安排在一条装配线上，多个产品能在各个阶段同时被加工

<span style='color: red'>**指令流水线**</span>：一条指令的处理过程分成若干个阶段，每个阶段由相应的功能部件完成



#### 两阶段方法

将指令处理分成两个阶段：取指令和执行指令

在当前指令的执行周期期间取下一条指令

问题：

1. 执行时间一般要长于取指时间
2. 主存访问冲突
3. 条件分支指令使得待取的下一条指令的地址是未知的



#### 六阶段方法

为了进一步的加速，流水线必须有更多的阶段

1. 取指令（Fetch instruction, FI）：读下一条预期的指令到缓冲器
2. 译码指令（Decode instruction, DI）：确定操作码和操作数指定符
3. 计算操作数（Calculate operands, CO）：计算每个源操作数的有效地址
4. 取操作数（Fetch operands, FO）：从存储器取出每个操作数，寄存器中的操作数**不需要取**
5. 执行指令（Execute instruction, EI）：完成指定的操作。若有指定的目的操作数位置，则将结果写入此位置
6. 写操作数（Write operand, WO）：将结果存入存储器

各个阶段所需要的时间几乎是相等的（**但并没有完全相等**）。



不是所有指令都包含6个阶段

* 例：一条LOAD指令不需要WO阶段
* 为了简化流水线硬件设计，在假定每条指令都要求这6个阶段的基础上来建立时序

不是所有阶段都能并行完成

* 例：FI/FO/WO都涉及存储器访问

若6个阶段不全是相等的时间，则会在各个流水线阶段涉及某种等待

限制：

1. 条件转移指令能使若干指令的读取变为无效

	![image-20220106213139814](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106213139814.png)

2. 中断 -- 流水线失效

	![image-20220106213133342](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106213133342.png)

#### 流水线性能

假设

* $t_i$：流水线第 $i$ 段的电路延迟时间
* $t_m$：最大段延迟（通过耗时最长段的延迟）
* $k$：指令流水线段数
* $d$：锁存延时（数据和信号从上一段送到下一段所需的段间锁存接收时间）

<span style='color: red'>**周期时间**</span>
$$
t = \max[t_i] + d = t_m + d
$$
令 $T_{k, n}$ 为 $k$ 阶段流水线执行所有 $n$ 条指令所需的总时间，那么：
$$
T_{k,n} = [k+(n-1)]t
$$
**加速比**：
$$
S_k = \frac{T_{1,n}}{T_{k,n}} = \frac{nkt}{[k+(n-1)]t} = \frac{nk}{k + (n-1)} = \frac{n}{1 + \frac{n-1}{k}}
$$

* 误解：流水线中的阶段数越多，执行速度越快
* 原因：
	* 在流水线的每个阶段，将数据从一个缓冲区移动到另一个缓冲区以及执行各种准备和传递功能都涉及一些开销
	* 处理内存和寄存器依赖以及优化管道使用所需的控制逻辑数量随着阶段的增加而急剧增加



### 流水线冒险

在某些情况下，指令流水线会阻塞或停顿（stall），导致后续指令无法正确执行。

类型

1. 结构冒险（Structure hazard）/ 硬件资源冲突

	> 也叫资源冒险（resource hazard）

2. 数据冒险（Data hazard）/ 数据依赖性

3. 控制冒险（Control hazard）



#### 结构冒险

原因：已进入流水线的不同指令在同一时刻访问相同的硬件资源

解决：使用多个不同的硬件资源，或者分时使用同一个硬件资源（分时复用，上升沿和下降沿交给不同的指令）

> Cache的引入和数据Cache与代码Cache



#### 数据冒险

原因：未生成指令所需要的数据

解决方案：

1. 插入`nop`指令，即什么都不做的指令，让需要前面数据的指令延时进行

	> 坏处：时间的浪费

2. 插入bubble（硬件控制）

	> 坏处：时间的浪费

3. 转发（forwarding）/ 旁路（bypassing）

	> 将`ALU`得到的结果就直接用于接下来的指令。（只能用于后面所用的数据时前面用`ALU`计算而出的
	>
	> 不足：无法解决`LOAD`指令所带来的问题

4. 交换指令顺序



#### 控制冒险

原因：指令的执行顺序被更改

1. 转移（Transfer）：分支（branch），循环（loop），...
2. 中断（Interrupt）
3. 异常（Exception）
4. 调用 / 返回（Call / Return）

解决：取多条指令

* 多个指令流：复制流水线的开始部分，并允许流水线同时取这两条指令，使用两个指令流
* 预取分支目标：识别出一个条件分支指令时，除了取此分支指令之后的指令外，分支目标处的指令也被取来
* 循环缓冲器：由流水线指令取指阶段维护的一个小的但极高速的存储器，含有 n 条最近顺序取来的指令

> 问题：多次分支会导致流水线数目不断增长膨胀，无法控制

解决：分支预测

* 静态预测
	* 预测绝不发生
	* 预测总是发生
	* 依操作码预测
* 动态预测
	* 发生 / 不发生切换
	* 转移历史表

![image-20220106213849418](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106213849418.png)

![image-20220106213901647](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220106213901647.png)

***



## 16 控制器

### 寄存器分类

1. 用户可见寄存器

> user-visible register

允许编程人员通过机器语言或汇编语言访问，通过优化寄存器的使用而**减少对主存的访问**

2. 控制和状态寄存器

> control and status register

* 由控制器来控制CPU的操作，并由拥有特权的操作系统程序来控制程序的执行

* 大多数控制和状态寄存器在大多数机器上是用户不可见的

	> 某些在控制或操作系统模式下执行的机器指令是用户可见的



**Tips:** 两者的区分并不严格



#### 用户可见寄存器

1. 通用寄存器 (general-purpose register)

	> 可被程序员指派各种用途

2. 数据寄存器 (data register)

	> 仅可用于保存数据而不能用于操作数地址的计算

3. 地址寄存器 (address register)

	> 可以使自身有某种通用性，或是专用于某种具体的寻址方式
	>
	> 例如：段指针，变址寄存器，栈指针

4. 条件码寄存器 (condition codes register) / 标志 (flag) 寄存器

	> CPU硬件设置这些条件位作为操作的结果
	>
	> 至少是部分用户可见的
	>
	> **并非所有机器都有**

##### 设计出发点

使用完全通用的寄存器还是规定各寄存器的用途

**寄存器数量**

1. 太少的寄存器会导致更多的存储器访问
2. 太多的寄存器又不能显著地减少存储器访问

**寄存器长度**

1. 应该要能保存大多数数据类型的值
2. 某些机器允许两个相邻的寄存器作为一个寄存器来保持两倍长度的值



##### 保存和恢复

子程序调用会导致自动保存所有用户可见的寄存器，并在返回时自动取回

* 这些保存和恢复是作为调用和返回指令执行功能的一部分，由CPU完成
* 这允许各个子程序独立地使用用户可见寄存器

子程序调用之外保存用户可见寄存器的相关内容是程序员的责任，需要在程序中为此编写专门的命令



#### 控制和状态寄存器

1. 程序计数器（Program counter, PC）
	* 存有待取指令的地址
	* 通常在每次取指令之后，PC的内容即被CPU更改，转移或跳步指令也会修改PC的内容，因此总指向被执行的下一条指令
2. 指令寄存器（Instruction register, IR）
	* 存有最近取来的指令，在其中分析操作码和操作数
3. 存储器地址寄存器（Memory address register, MAR）
	* 直接与地址总线相连，存有存储器位置的地址
4. 存储器缓冲寄存器（Memory buffer register, MBR）
	* 直接与数据总线相连，存有将被写入存储器的数据字或从存储器读出的字，用户可见寄存器再与MBR交换数据
5. 程序状态字（Program status word, PSW）

  * 一个或一组包含状态信息的寄存器，包含条件码加上其他状态信息
  * 包含的字段或标志
   * 符号
   * 零
   * 进位
   * 等于
   * 溢出
   * 中断允许 / 禁止
   * 监管

6. 指针寄存器：指向附加状态信息的存储器块
7. 中断向量寄存器：
8. 系统栈指针：
9. 页表指针寄存器：



##### 设计出发点

**对操作系统的支持**

* 某些类型的控制信息是专门为操作系统使用的
* 若CPU设计者对将要使用的操作系统有基本的了解，则寄存器的组织可能在一定程度上为该操作系统定制

**控制信息在寄存器和存储器之间的分配**

* 一个普遍的做法是将存储器最前面（最低地址）的几百或几千个字用于控制母的
* 在成本和速度之间权衡





### 微操作

执行程序时，计算机操作是由一系列指令周期组成，每个周期执行一条机器指令

每个指令周期又可以看作是由几个更小的子周期组成

> 包括：取指，间址，执行，中断

每个子周期由一系列<span style='color: orange'>**涉及CPU寄存器操作**</span>的更小步骤组成，这些步骤称为<span style='color: red'>**微操作**</span>



#### 取指周期

出现在每个指令周期的开始，将指令从存储器中取出

> 这里会访问一次主存

![](https://s2.loli.net/2022/01/06/hJvGI31e4kQNrEf.png)



#### 间址周期

指令执行前会有一个间址周期，来读取有效地址（注意这里并没有读取操作数）

完成间址周期后，IR的状态与不使用间接寻址方式的状态是相同的，已经为执行周期准备就绪



#### 中断周期

在完成执行周期的时候，确定是否有允许的中断发生，如果有，则出现一个中断周期



#### 微操作分组的原则

1. 事件的流动顺序必须是恰当的

	> 例：MAR <- (PC) 必须先于 MBR <- 主存，因为主存读操作需要用到MAR中的地址

2. 必须避免冲突

	> MBR <- 内存 和 IR <- MBR 这两个微操作不应该出现在同一时间里

3. 满足上述条件的情况下，所用的单位时间尽可能少



#### 指令周期代码（Instruction Cycle Code, ICC）

* 取指、间址、中断周期各有一个微操作序列，执行周期则对于每个操作码有一个微操作序列

* 指令周期代码：假设一个2位的ICC寄存器，明确CPU处于指令周期的哪个阶段

	> 00：取指，01：间址，10：执行，11：中断

	![image-20211219194052302](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211219194052302.png)



#### CPU内部总线

1. ALU和寄存器都连接到CPU内部总线上
2. 为了数据在该内部总线和各寄存器之间传递，内部总线和寄存器之间有门和控制信号
3. 控制线控制着数据和系统总线（外部）的交换以及ALU的操作

> 一时间在CPU内部总线上只能够有一个数据，否则多个数据会混淆起来

![image-20220107091204447](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107091204447.png)

![image-20220107091213879](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107091213879.png)

> $t_3,t_4$ 不能合并的原因是因为MBR传输和AC传输都需要CPU内部总线，所以两者必须要分时进行 



### 控制器

#### 控制CPU的功能需求

CPU的基本元素：ALU，寄存器组，内部数据通路，控制器，外部数据通路

CPU需要完成的微操作：

1. 再寄存器之间传送数据
2. 将数据由寄存器传送到外部接口（如系统总线）
3. 将数据由外部接口传送到寄存器
4. 将寄存器作为输入和输出，完成算术和逻辑运算

控制器的两个基本任务：

1. 定序：根据正被执行的程序，控制器使CPU以正确的顺序通过一系列微操作
2. 执行：控制器使每个微操作得以完成



#### 控制器的输入

**指令寄存器**：当前指令的寻址方式和操作码

**标志**：确定CPU的状态和前一个ALU操作的结果

**时钟**：控制器要在每个时钟脉冲完成一个或一组同时的微操作

**来自控制总线的控制信号**：向控制器提供控制信号

> 例：中断请求



#### 控制器的输出

**CPU内的控制信号**

* 用于寄存器之间传送数据
* 用于启动特定的ALU功能

**到控制总线的控制信号**

* 到存储器的控制信号
* 到I/O模块的控制信号

> 所有的控制信号最终作为二进制输入量直接输入到各个逻辑门上
>
> 即到逻辑门上的信号要么是 $0$ 要么是 $1$



##### 控制信号示例：取指周期

![image-20220107091737447](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107091737447.png)

![image-20220107091742633](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107091742633.png)

> 1. 传送PC的内容到MAR
> 	* 打开 $C_2$：PC传到MAR
> 2. 由存储器读一条指令装入MBR，并且递增PC
> 	* 打开 $C_0$：MAR的内容送到地址总线上
> 	* 存储器读控制信号 $C_R$（图中未体现）送到控制总线上
> 	* 打开 $C_5$：数据总线上的内容存入MBR
> 	* 控制信号对PC内容加一（指令长度）并把结果存回PC
> 3. 传送MBR的内容到IR
> 	* 打开 $C_4$：MBR的内容送到IR



#### 控制器的最小特性

控制器只需要知道将被执行的指令和算术、逻辑运算结果的性质（如正负、溢出等），而不需要知道正被处理的数据获得到的实际结果具体是什么

控制器只是以少量的送到CPU内的和送到系统总线上的控制信号来实现控制



#### 控制器的实现

* 硬布线实现（hardwired implementation）
	* 控制器是一个组合电路，把输入逻辑信号转换为一组输出逻辑信号，即控制信号
* 微程序实现（microprogammed implementation）
	* 控制逻辑是微程序指定的，控制器通过执行微程序里的每一条微指令来实现控制



##### 硬布线实现：控制器输入

标志和控制总线信号：每位都有特定的意义

指令寄存器：

1. 通过译码，使每一操作码有一个唯一的逻辑输入

2. 译码器有 $n$ 个输入和 $2^n$ 个输出

	> 控制器要考虑变长的操作码，译码器会更复杂一些

**时钟**：

1. 在一个指令周期内控制周期要在不同时间单位发送不同的控制信号
2. 使用一个定时器作为控制器的输入，并且控制器在指令周期结束时必须通知定时器以使其重新开始计数（子周期内递增，子周期结束就应该清零）



##### 硬布线实现：控制器逻辑

1. 为每个输出的控制信号设计一个关于控制器输入的布尔表达式

2. 定义两个新的控制信号 $P$ 和 $Q$

	> $PQ = 00$：取指周期，$PQ = 01$：间址周期， $PQ = 10$：执行周期，$PQ = 11$：中断周期

	![image-20211219195612170](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20211219195612170.png) 

（注：乘是与，加是或）

（LDA：LOAD指令，ADD：ADD指令，AND：AND指令）



##### 微程序实现：基本概念和思路

微程序（固件）介于硬件和软件之间

* 设计固件比设计硬件容易，但写固件程序比软件程序困难
* 微指令序列

**微指令**：每行描述一个时间内出现的一组微操作

**基本思路**：

1. 对于每个微操作，控制器的任务是产生一组控制信号，即控制器发出的每根控制线或开或关（每根控制线由一个二进制数字表示）
2. 构造一个控制字，每位代表一根控制线，这样每个微操作能用控制字中的不同的 $0$ 和 $1$ 的样式来表示
3. 将这些控制字在一起，可以表示控制器需要完成的微操作序列



* 由于微操作序列不是固定的，把控制字放入一个存储器单元中，每个字有自己唯一的地址

	* 添加少数几位用于指示条件的真假

		> 若条件位指示的条件为假，则顺序执行下一条指令
		>
		> 若条件位指示的条件为真，则地址字段指向的微指令是将被执行的下一条微指令

	* 给每个控制字添加一个地址字段，以指示某种条件为真时，将要执行的下一控制字的位置



##### 微程序控制器：任务

**微指令定序**（microinstruction sequencing）

* 根据当前的微指令、条件标志和指令寄存器的内容，产生下一微指令的控制存储器的地址
* 设计考虑
	* 微指令的大小：减小微指令的大小就能节省控制存储器的成本
	* 地址生成空间：尽可能地执行微指令

**微指令执行**（microinstruction execution）

* 产生控制信号：发往CPU内部，送往外部控制总线或其他外部接口



##### 微程序控制器：构成

1. 定序逻辑：向控制地址寄存器装入地址，并发出读命令
2. 控制地址寄存器：含有下面即将被读取的微指令地址
3. 控制存储器：存有一组微指令
4. 控制缓冲寄存器：存放被读出的微指令

***



## 17 输入输出

### 外围设备

输入/输出操作通过连接到输入输出模块的各种外部设备完成，这些外部设备提供了在外部环境和计算机系统之间的数据交换，通常被称为<span style='color: orange'>**外围设备**</span>（peripheral device），简称为外设

类型：

* 人可读设备：适用于与计算机用户通信
	* 显示器，打印机，......
* 机器可读设备：适用于与设备通信
	* 磁带，磁盘，......
* 通信设备：适用于与远程设备通信



### 为什么不能把外设直接连接到系统总线上

1. 外设种类繁多，操作方法多种多样
2. 外设的数据传送速度一般比存储器或处理器的慢很多
3. 某些外设的数据传送速度比存储器或处理器要快
4. 外设使用的数据格式和字长度通常与处理器不同



### I/O 模块

通过系统总线或中央交换器和存储器连接，通过专用数据线与一个或多个外设连接。<span style='color: red'>**I/O模块是计算机内部系统和外设之间的桥梁**</span>

![image-20220107094043044](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107094043044.png)

#### 外围设备的接口

* 输入/输出模块的接口以控制、状态和数据信号的形式出现
* 与设备相关的控制逻辑控制外设的操作，以响应来自输入/输出模块的命令
* 缓冲器用于缓存输入/输出模块和外设之间传送的数据
	* 缓冲器的大小一般为8位或16位

![image-20220107094209776](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107094209776.png)

#### I/O 模块的功能

**处理器通信：**

1. 命令译码：输入/输出模块接收来自处理器的命令，这些命令一般作为信号发送到控制总线
2. 数据：数据是在处理器和输入/输出模块之间经由数据总线来交换的
3. 状态报告：由于外设速度很慢，所以知道输入/输出模块的状态很重要
4. 地址识别：输入/输出模块必须能识别它所控制的每个外设的唯一地址

**设备通信：**

* 通信内容包括命令、状态信息和数据

**数据缓冲：**

1. 外设的数据传送速度一般比存储器或处理器的慢得多
2. 某些外设的数据传送速度比存储器或处理器要快

**控制和定时：**

1. 处理器会非预期的与一个或几个外设进行通信
2. 一些内部资源，如主存和系统总线，是被共享的
3. 例如：控制从外设到处理器的数据传送包括以下几个步骤
	* 处理器查询I/O模块以检验所连接设备的状态
	* I/O模块返回设备状态
	* 如果设备运转并准备就绪，则处理器通过向I/O模块发出一条命令，请求数据传送
	* 数据从I/O模块传送到处理器

**检错：**

1. 检错并把差错信息报告给处理器
2. 差错类型：
	* 设备报告的机械和电路故障
	* 传输过程中数据位的变化



#### I/O 模块的结构

![image-20220107094810755](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107094810755.png)

##### 外部接口

**接口类型**：

1. 并行接口：多根线连接I/O模块和外设，同时传送多位数据
2. 串行接口：只有一根线用于传输数据，每次只传输一位数据

> 由于并行接口要求每次同时传送，当传输速度和总线长度增加时，总线的时钟频率会受到限制



### I/O 操作技术

1. **编程式I/O**：处理器通过执行程序来直接控制I/O操作，当处理器发送一条命令到I/O模块时，它必须等待，直到I/O操作完成
2. **中断驱动式I/O**：处理器发送一条I/O命令后，继续执行其他指令；并且当I/O模块完成其工作后，才去中断处理器工作
3. **直接存储器读取**（Direct Memory Access, DMA）：I/O模块与主存直接交换数据，而不需要处理器的干涉。

![image-20220107095235362](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107095235362.png)

#### 编程式I/O

* 当处理器在执行过程中遇到一条与I/O操作有关的指令时，它通过发送指令到适当的I/O模块来执行这条指令
* I/O模块将执行所要求的的动作，然后在I/O状态寄存器中设置一些适当的位
* I/O**不会中断**处理器，因此处理器需要周期性地检查I/O的状态，直到发现该操作完成。

![image-20220107095418865](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107095418865.png)

##### I/O 命令

* 为了执行I/O操作，处理器发送一个指定具体I/O模块和外设的地址，并发送一条<span style='color: red'>**I/O命令**</span>
* 类型
	* 控制命令：激活外设并告诉它要做什么
	* 测试命令：测试I/O模块及其外设相关的各种状态条件
	* 读命令：使I/O模块从外设获得一个数据，把它存入内存缓冲区
	* 写命令：使I/O模块从数据总线获得一个数据，把它传入外设

##### I/O 指令

* I/O指令很容易映射为I/O命令，并且两者之间通常是简单的一一对应关系

	> 指令的形式取决于外设寻址的方式

* 编址方式

	* 存储器映射式I/O：存储单元和I/O设备有统一的地址空间

		> 能使用大的指令系统，可进行更有效的编程

	* 分离式I/O：让总线既有存储器的读线和写线，同时也有输入和输出命令线



#### 中断驱动式I/O

* 处理器发送一个I/O命令到模块，然后去处理其他有用的工作
* 当I/O模块准备和处理器交换数据时，它中断处理器以请求服务
* 处理器执行数据传送，最后恢复它原先的处理工作

![image-20220107202550387](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107202550387.png)

**从I/O模块的角度来看**

* I/O模块接收来自处理器的读命令
* I/O模块从相关的外设中读入数据
* 一旦数据进入I/O模块的数据寄存器后，该模块通过控制总线给处理器发送中断信号
* I/O模块等待直到处理器请求该数据为止
* 当处理器有数据请求时，I/O模块把数据传送到数据总线上，并准备另一个I/O操作

**从处理器角度看**

* 处理器发送一个读命令
* 处理器离开去做其他的事情，并在每个指令周期结束时检查中断
* 当来自I/O模块的中断出现时，处理器保存当前程序的现场
* 处理器从I/O模块读取数据字并保存到主存中
* 处理器恢复刚才正在运行的程序的现场，并继续运行原来的程序



##### 中断允许和中断禁止

![image-20220107203001055](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107203001055.png)

##### 响应优先级和处理优先级

> 例子：假设中断系统中有4个中断源，其<span style='color: orange'>**响应优先级**</span>为 $L_1 > L_2 > L_3 > L_4$，<span style='color: orange'>**处理优先级**</span>为 $L_1 > L_4 > L_3 > L_2$。如果主程序执行时同时发生 $L_1, L_3$ 和 $L_4$ 中断，并且在处理 $L_3$ 中断的过程中发生 $L_2$ 中断，写出<span style='color: green'>**掩码字**</span>和所有中断服务程序的过程

> 注：主程序的优先级是最低的
>
> 注：掩码字/屏蔽字：即如果某个中断程序可以对另一个中断程序屏蔽（处理优先级高），则标记为1

![image-20220107203423758](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107203423758.png)

**过程描述**

1. 主程序运行时，$L_1,L_3,L_4$发生，响应优先级最高的是 $L_1$ ，因此先中断执行 $L_1$，因为 $L_1$ 也是处理优先级最高的，所以不会被其他中断源所中断
2. 执行完 $L_1$ 之后，要**恢复主程序的现场**（这个时间段是中断禁止的），回复完毕之后，响应优先级最高的 $L_3$ 率先执行，但因为其处理优先级比 $L_4$，低，所以被**嵌套中断**，然后 $L_4$ 执行完后**恢复 $L_3$ 的现场**并继续执行 $L_3$
3. 此时 $L_2$ 也请求中断，但因为其处理优先级最低，没办法中断 $L_3$，因此 $L_3$ 执行完后**恢复主程序现场**，然后被 $L_2$ 中断并执行完 $L_2$



##### 设备识别

* 多条中断线：即使有多条中断线可用，每条线上也需要采用其它三种技术中的一种
* 软件轮询：轮询每一个I/O模块来确定是哪个模块发生的中断
* 菊花链：所有的I/O模块共享一条中断请求线，中断应答线采用菊花链穿过这些中断模块
* 独立请求：特定的中断控制器用于阶码和分析优先级



##### 分配优先级

* 多条中断线：处理器仅仅挑选具有最高优先级的中断线
* 软件轮询：模块的轮询次序就决定了模块的优先级
* 菊花链：链接模块次序就决定了模块的优先级
* 独立请求：中断控制器决定



#### 直接存储器读取（DMA）

**编程式I/O和中断驱动式I/O的不足**

1. I/O传送速度受处理器测试和服务设备速度的限制
2. 处理器负责管理I/O传送，对于每一次I/O传送，处理器必须执行很多指令

**直接存储器存取**：无需经过处理器即可直接访问内存的模块

![image-20220107204801841](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107204801841.png)

* 处理器通过发送以下信息向DMA模块发出命令：读/写，I/O设备地址，内存中的起始位置，字数
* 处理器继续进行其它工作
* DMA模块将全部数据块，每次一个字，直接将数据传输到存储器或从存储器读出，而无需经过处理器
* 当传输完成时，DMA模块向处理器发送一个中断信号



##### DMA内存访问

###### CPU停止法

![image-20220107205025667](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107205025667.png)

* 优点：控制简单
* 缺点：影响CPU，没有充分利用内存
* 适用：高速I/O设备的块传输

###### 周期窃取

![image-20220107205111529](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107205111529.png)

* 优点：充分利用CPU和内存，及时响应I/O请求
* 缺点：DMA每次都请求总线
* 适用：I/O周期大于存储周期

###### 交替分时访问

![image-20220107205208317](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107205208317.png)

* 优点：CPU未停止或等待，DMA不请求总线

* 缺点：CPU周期大于存储周期



##### DMA配置机制

###### 单总线分离DMA

* 所有模块共享相同的系统总线
* DMA模块使用编程式I/O，通过DMA模块在存储器和I/O模块之间交换数据
* 便宜但低效

![image-20220107205604288](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107205604288.png)

###### 单总线集合的DMA-I/O

* DMA逻辑实际上可能是I/O模块的一部分，也可能是控制一个或多个I/O模块的单独模块
* 减少总线周期数

![image-20220107205651670](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107205651670.png)

###### I/O总线

* 使用I/O总线将I/O模块连接到DMA模块
* 多个I/O模块共享DMA，且易于扩展

![image-20220107205726115](C:/Users/Zyi/AppData/Roaming/Typora/typora-user-images/image-20220107205726115.png)



## 18 课程小结

### 一些单位的换算

1. $1ns = 10^{-9}s, 1ms =10^{-3}s, 1 \mu s = 10^{-6}s$
2. $1bps = 10^{-6} Mbps$
3. $1Hz = 10^{-6}MHz = 10^{-9}GHz$
